--- a/ayrton/parser/astcompiler/assemble.py
+++ b/ayrton/parser/astcompiler/assemble.py
@@ -1,14 +1,9 @@
 """Python control flow graph generation and bytecode assembly."""
 
 import os
-from rpython.rlib import rfloat
-from rpython.rlib.objectmodel import specialize, we_are_translated
 
-from pypy.interpreter.astcompiler import ast, consts, misc, symtable
-from pypy.interpreter.error import OperationError
-from pypy.interpreter.pycode import PyCode
-from pypy.interpreter.miscutils import string_sort
-from pypy.tool import stdlib_opcode as ops
+from ayrton.parser.astcompiler import ast, consts, misc, symtable
+from ayrton.parser.error import OperationError
 
 
 class StackDepthComputationError(Exception):
@@ -565,7 +560,7 @@
 
 def _list_from_dict(d, offset=0):
     result = [None] * len(d)
-    for obj, index in d.iteritems():
+    for obj, index in d.items():
         result[index - offset] = obj
     return result
 
@@ -777,7 +772,7 @@
     if name.startswith("_compute_"):
         func._always_inline_ = True
         _stack_effect_computers[getattr(ops, name[9:])] = func
-for op, value in _static_opcode_stack_effects.iteritems():
+for op, value in _static_opcode_stack_effects.items():
     def func(arg, _value=value):
         return _value
     func._always_inline_ = True
--- a/ayrton/parser/astcompiler/astbuilder.py
+++ b/ayrton/parser/astcompiler/astbuilder.py
@@ -1,23 +1,15 @@
-from pypy.interpreter.astcompiler import ast, consts, misc
-from pypy.interpreter.astcompiler import asthelpers # Side effects
-from pypy.interpreter.astcompiler import fstring
-from pypy.interpreter import error
-from pypy.interpreter.pyparser.pygram import syms, tokens
-from pypy.interpreter.pyparser.error import SyntaxError
-from rpython.rlib.objectmodel import always_inline, we_are_translated
+from ayrton.parser.astcompiler import consts, misc
+from ayrton.parser.astcompiler import fstring
+from ayrton.parser import error
+from ayrton.parser.pyparser.pygram import syms, tokens
+from ayrton.parser.pyparser.error import SyntaxError
+import ast
+from ast import Starred
 
 
-def ast_from_node(space, node, compile_info, recursive_parser=None):
+def ast_from_node(space, node, compile_info):
     """Turn a parse tree, node, to AST."""
-    ast = ASTBuilder(space, node, compile_info, recursive_parser).build_ast()
-    #
-    # When we are not translated, we send this ast to validate_ast.
-    # The goal is to check that validate_ast doesn't crash on valid
-    # asts, at least.
-    if not we_are_translated():
-        from pypy.interpreter.astcompiler import validate
-        validate.validate_ast(space, ast)
-    return ast
+    return ASTBuilder(space, node, compile_info).build_ast()
 
 
 augassign_operator_map = {
@@ -52,37 +44,47 @@
 })
 
 
+expression_name_map = {
+    ast.Attribute: 'attr',
+    ast.Name: 'id',
+}
+
+
+def parsestr(space, encoding, literal):
+    # return space.wrap(eval (literal))
+    return eval (literal)
+
+
 class ASTBuilder(object):
 
-    def __init__(self, space, n, compile_info, recursive_parser=None):
+    def __init__(self, space, n, compile_info):
         self.space = space
         self.compile_info = compile_info
         self.root_node = n
-        self.recursive_parser = recursive_parser
 
     def build_ast(self):
         """Convert an top level parse tree node into an AST mod."""
         n = self.root_node
         if n.type == syms.file_input:
             stmts = []
-            for i in range(n.num_children() - 1):
-                stmt = n.get_child(i)
+            for i in range(len(n.children) - 1):
+                stmt = n.children[i]
                 if stmt.type == tokens.NEWLINE:
                     continue
                 sub_stmts_count = self.number_of_statements(stmt)
                 if sub_stmts_count == 1:
                     stmts.append(self.handle_stmt(stmt))
                 else:
-                    stmt = stmt.get_child(0)
+                    stmt = stmt.children[0]
                     for j in range(sub_stmts_count):
-                        small_stmt = stmt.get_child(j * 2)
+                        small_stmt = stmt.children[j * 2]
                         stmts.append(self.handle_stmt(small_stmt))
             return ast.Module(stmts)
         elif n.type == syms.eval_input:
-            body = self.handle_testlist(n.get_child(0))
+            body = self.handle_testlist(n.children[0])
             return ast.Expression(body)
         elif n.type == syms.single_input:
-            first_child = n.get_child(0)
+            first_child = n.children[0]
             if first_child.type == tokens.NEWLINE:
                 # An empty line.
                 return ast.Interactive([])
@@ -92,8 +94,8 @@
                     stmts = [self.handle_stmt(first_child)]
                 else:
                     stmts = []
-                    for i in range(0, first_child.num_children(), 2):
-                        stmt = first_child.get_child(i)
+                    for i in range(0, len(first_child.children), 2):
+                        stmt = first_child.children[i]
                         if stmt.type == tokens.NEWLINE:
                             break
                         stmts.append(self.handle_stmt(stmt))
@@ -107,16 +109,16 @@
         if stmt_type == syms.compound_stmt:
             return 1
         elif stmt_type == syms.stmt:
-            return self.number_of_statements(n.get_child(0))
+            return self.number_of_statements(n.children[0])
         elif stmt_type == syms.simple_stmt:
             # Divide to remove semi-colons.
-            return n.num_children() // 2
+            return len(n.children) // 2
         else:
             raise AssertionError("non-statement node")
 
     def error(self, msg, n):
-        """Raise a SyntaxError with the lineno and column set to n's."""
-        raise SyntaxError(msg, n.get_lineno(), n.get_column(),
+        """Raise a SyntaxError with the lineno and col_offset set to n's."""
+        raise SyntaxError(msg, n.lineno, n.col_offset,
                           filename=self.compile_info.filename)
 
     def error_ast(self, msg, ast_node):
@@ -134,42 +136,68 @@
 
     def set_context(self, expr, ctx):
         """Set the context of an expression to Store or Del if possible."""
+        t = type(expr)
         try:
-            expr.set_context(ctx)
-        except ast.UnacceptableExpressionContext as e:
-            self.error_ast(e.msg, e.node)
+            # TODO: check if Starred is ok
+            if t in (ast.Attribute, ast.Name):
+                if type(ctx) == ast.Store():
+                    mis.check_forbidden_name(getattr (expr, expression_name_map[t]), expr)
+            elif t in (ast.Subscript, ast.Starred):
+                pass
+            elif t in (ast.List, ast.Tuple):
+                for elt in expr.elts:
+                    self.set_context(elt, ctx)
+            expr.ctx = ctx
         except misc.ForbiddenNameAssignment as e:
             self.error_ast("cannot assign to %s" % (e.name,), e.node)
 
     def handle_del_stmt(self, del_node):
-        targets = self.handle_exprlist(del_node.get_child(1), ast.Del)
-        return ast.Delete(targets, del_node.get_lineno(), del_node.get_column())
+        targets = self.handle_exprlist(del_node.children[1], ast.Del())
+        new_node = ast.Delete (targets)
+        new_node.lineno = ( del_node.lineno)
+        new_node.col_offset = del_node.col_offset
+        return new_node
 
     def handle_flow_stmt(self, flow_node):
-        first_child = flow_node.get_child(0)
+        first_child = flow_node.children[0]
         first_child_type = first_child.type
         if first_child_type == syms.break_stmt:
-            return ast.Break(flow_node.get_lineno(), flow_node.get_column())
+            new_node = ast.Break ()
+            new_node.lineno = flow_node.lineno
+            new_node.col_offset = flow_node.col_offset
+            return new_node
         elif first_child_type == syms.continue_stmt:
-            return ast.Continue(flow_node.get_lineno(), flow_node.get_column())
+            new_node = ast.Continue ()
+            new_node.lineno = flow_node.lineno
+            new_node.col_offset = flow_node.col_offset
+            return new_node
         elif first_child_type == syms.yield_stmt:
-            yield_expr = self.handle_expr(first_child.get_child(0))
-            return ast.Expr(yield_expr, flow_node.get_lineno(), flow_node.get_column())
+            yield_expr = self.handle_expr(first_child.children[0])
+            new_node = ast.Expr (yield_expr)
+            new_node.lineno = flow_node.lineno
+            new_node.col_offset = flow_node.col_offset
+            return new_node
         elif first_child_type == syms.return_stmt:
-            if first_child.num_children() == 1:
+            if len(first_child.children) == 1:
                 values = None
             else:
-                values = self.handle_testlist(first_child.get_child(1))
-            return ast.Return(values, flow_node.get_lineno(), flow_node.get_column())
+                values = self.handle_testlist(first_child.children[1])
+            new_node = ast.Return (values)
+            new_node.lineno = flow_node.lineno
+            new_node.col_offset = flow_node.col_offset
+            return new_node
         elif first_child_type == syms.raise_stmt:
             exc = None
             cause = None
-            child_count = first_child.num_children()
+            child_count = len(first_child.children)
             if child_count >= 2:
-                exc = self.handle_expr(first_child.get_child(1))
+                exc = self.handle_expr(first_child.children[1])
             if child_count >= 4:
-                cause = self.handle_expr(first_child.get_child(3))
-            return ast.Raise(exc, cause, flow_node.get_lineno(), flow_node.get_column())
+                cause = self.handle_expr(first_child.children[3])
+            new_node = ast.Raise (exc, cause)
+            new_node.lineno = flow_node.lineno
+            new_node.col_offset = flow_node.col_offset
+            return new_node
         else:
             raise AssertionError("unknown flow statement")
 
@@ -177,33 +205,33 @@
         while True:
             import_name_type = import_name.type
             if import_name_type == syms.import_as_name:
-                name = self.new_identifier(import_name.get_child(0).get_value())
-                if import_name.num_children() == 3:
+                name = self.new_identifier(import_name.children[0].value)
+                if len(import_name.children) == 3:
                     as_name = self.new_identifier(
-                        import_name.get_child(2).get_value())
-                    self.check_forbidden_name(as_name, import_name.get_child(2))
+                        import_name.children[2].value)
+                    self.check_forbidden_name(as_name, import_name.children[2])
                 else:
                     as_name = None
-                    self.check_forbidden_name(name, import_name.get_child(0))
+                    self.check_forbidden_name(name, import_name.children[0])
                 return ast.alias(name, as_name)
             elif import_name_type == syms.dotted_as_name:
-                if import_name.num_children() == 1:
-                    import_name = import_name.get_child(0)
+                if len(import_name.children) == 1:
+                    import_name = import_name.children[0]
                     continue
-                alias = self.alias_for_import_name(import_name.get_child(0),
+                alias = self.alias_for_import_name(import_name.children[0],
                                                    store=False)
-                asname_node = import_name.get_child(2)
-                alias.asname = self.new_identifier(asname_node.get_value())
+                asname_node = import_name.children[2]
+                alias.asname = self.new_identifier(asname_node.value)
                 self.check_forbidden_name(alias.asname, asname_node)
                 return alias
             elif import_name_type == syms.dotted_name:
-                if import_name.num_children() == 1:
-                    name = self.new_identifier(import_name.get_child(0).get_value())
+                if len(import_name.children) == 1:
+                    name = self.new_identifier(import_name.children[0].value)
                     if store:
-                        self.check_forbidden_name(name, import_name.get_child(0))
+                        self.check_forbidden_name(name, import_name.children[0])
                     return ast.alias(name, None)
-                name_parts = [import_name.get_child(i).get_value()
-                              for i in range(0, import_name.num_children(), 2)]
+                name_parts = [import_name.children[i].value
+                              for i in range(0, len(import_name.children), 2)]
                 name = ".".join(name_parts)
                 return ast.alias(name, None)
             elif import_name_type == tokens.STAR:
@@ -212,20 +240,23 @@
                 raise AssertionError("unknown import name")
 
     def handle_import_stmt(self, import_node):
-        import_node = import_node.get_child(0)
+        import_node = import_node.children[0]
         if import_node.type == syms.import_name:
-            dotted_as_names = import_node.get_child(1)
-            aliases = [self.alias_for_import_name(dotted_as_names.get_child(i))
-                       for i in range(0, dotted_as_names.num_children(), 2)]
-            return ast.Import(aliases, import_node.get_lineno(), import_node.get_column())
+            dotted_as_names = import_node.children[1]
+            aliases = [self.alias_for_import_name(dotted_as_names.children[i])
+                       for i in range(0, len(dotted_as_names.children), 2)]
+            new_node = ast.Import (aliases)
+            new_node.lineno = import_node.lineno
+            new_node.col_offset = import_node.col_offset
+            return new_node
         elif import_node.type == syms.import_from:
-            child_count = import_node.num_children()
+            child_count = len(import_node.children)
             module = None
             modname = None
             i = 1
             dot_count = 0
             while i < child_count:
-                child = import_node.get_child(i)
+                child = import_node.children[i]
                 child_type = child.type
                 if child_type == syms.dotted_name:
                     module = self.alias_for_import_name(child, False)
@@ -239,16 +270,16 @@
                 i += 1
                 dot_count += 1
             i += 1
-            after_import_type = import_node.get_child(i).type
+            after_import_type = import_node.children[i].type
             star_import = False
             if after_import_type == tokens.STAR:
-                names_node = import_node.get_child(i)
+                names_node = import_node.children[i]
                 star_import = True
             elif after_import_type == tokens.LPAR:
-                names_node = import_node.get_child(i + 1)
+                names_node = import_node.children[i + 1]
             elif after_import_type == syms.import_as_names:
-                names_node = import_node.get_child(i)
-                if names_node.num_children() % 2 == 0:
+                names_node = import_node.children[i]
+                if len(names_node.children) % 2 == 0:
                     self.error("trailing comma is only allowed with "
                                "surronding parenthesis", names_node)
             else:
@@ -256,251 +287,323 @@
             if star_import:
                 aliases = [self.alias_for_import_name(names_node)]
             else:
-                aliases = [self.alias_for_import_name(names_node.get_child(i))
-                           for i in range(0, names_node.num_children(), 2)]
+                aliases = [self.alias_for_import_name(names_node.children[i])
+                           for i in range(0, len(names_node.children), 2)]
             if module is not None:
                 modname = module.name
-            return ast.ImportFrom(modname, aliases, dot_count,
-                                  import_node.get_lineno(), import_node.get_column())
+            new_node = ast.ImportFrom (modname, aliases, dot_count)
+            new_node.lineno = import_node.lineno
+            new_node.col_offset = import_node.col_offset
+            return new_node
         else:
             raise AssertionError("unknown import node")
 
     def handle_global_stmt(self, global_node):
-        names = [self.new_identifier(global_node.get_child(i).get_value())
-                 for i in range(1, global_node.num_children(), 2)]
-        return ast.Global(names, global_node.get_lineno(), global_node.get_column())
+        names = [self.new_identifier(global_node.children[i].value)
+                 for i in range(1, len(global_node.children), 2)]
+        new_node = ast.Global (names)
+        new_node.lineno = global_node.lineno
+        new_node.col_offset = global_node.col_offset
+        return new_node
 
     def handle_nonlocal_stmt(self, nonlocal_node):
-        names = [self.new_identifier(nonlocal_node.get_child(i).get_value())
-                 for i in range(1, nonlocal_node.num_children(), 2)]
-        return ast.Nonlocal(names, nonlocal_node.get_lineno(), nonlocal_node.get_column())
+        names = [self.new_identifier(nonlocal_node.children[i].value)
+                 for i in range(1, len(nonlocal_node.children), 2)]
+        new_node = ast.Nonlocal (names)
+        new_node.lineno = nonlocal_node.lineno
+        new_node.col_offset = nonlocal_node.col_offset
+        return new_node
 
     def handle_assert_stmt(self, assert_node):
-        expr = self.handle_expr(assert_node.get_child(1))
+        expr = self.handle_expr(assert_node.children[1])
         msg = None
-        if assert_node.num_children() == 4:
-            msg = self.handle_expr(assert_node.get_child(3))
-        return ast.Assert(expr, msg, assert_node.get_lineno(), assert_node.get_column())
+        if len(assert_node.children) == 4:
+            msg = self.handle_expr(assert_node.children[3])
+        new_node = ast.Assert (expr, msg)
+        new_node.lineno = assert_node.lineno
+        new_node.col_offset = assert_node.col_offset
+        return new_node
 
     def handle_suite(self, suite_node):
-        first_child = suite_node.get_child(0)
+        first_child = suite_node.children[0]
         if first_child.type == syms.simple_stmt:
-            end = first_child.num_children() - 1
-            if first_child.get_child(end - 1).type == tokens.SEMI:
+            end = len(first_child.children) - 1
+            if first_child.children[end - 1].type == tokens.SEMI:
                 end -= 1
-            stmts = [self.handle_stmt(first_child.get_child(i))
+            stmts = [self.handle_stmt(first_child.children[i])
                      for i in range(0, end, 2)]
         else:
             stmts = []
-            for i in range(2, suite_node.num_children() - 1):
-                stmt = suite_node.get_child(i)
+            for i in range(2, len(suite_node.children) - 1):
+                stmt = suite_node.children[i]
                 stmt_count = self.number_of_statements(stmt)
                 if stmt_count == 1:
                     stmts.append(self.handle_stmt(stmt))
                 else:
-                    simple_stmt = stmt.get_child(0)
-                    for j in range(0, simple_stmt.num_children(), 2):
-                        stmt = simple_stmt.get_child(j)
-                        if not stmt.num_children():
+                    simple_stmt = stmt.children[0]
+                    for j in range(0, len(simple_stmt.children), 2):
+                        stmt = simple_stmt.children[j]
+                        if not stmt.children:
                             break
                         stmts.append(self.handle_stmt(stmt))
         return stmts
 
     def handle_if_stmt(self, if_node):
-        child_count = if_node.num_children()
+        child_count = len(if_node.children)
         if child_count == 4:
-            test = self.handle_expr(if_node.get_child(1))
-            suite = self.handle_suite(if_node.get_child(3))
-            return ast.If(test, suite, None, if_node.get_lineno(), if_node.get_column())
-        otherwise_string = if_node.get_child(4).get_value()
+            test = self.handle_expr(if_node.children[1])
+            suite = self.handle_suite(if_node.children[3])
+            new_node = ast.If (test, suite, [])
+            new_node.lineno = if_node.lineno
+            new_node.col_offset = if_node.col_offset
+            return new_node
+        otherwise_string = if_node.children[4].value
         if otherwise_string == "else":
-            test = self.handle_expr(if_node.get_child(1))
-            suite = self.handle_suite(if_node.get_child(3))
-            else_suite = self.handle_suite(if_node.get_child(6))
-            return ast.If(test, suite, else_suite, if_node.get_lineno(),
-                          if_node.get_column())
+            test = self.handle_expr(if_node.children[1])
+            suite = self.handle_suite(if_node.children[3])
+            else_suite = self.handle_suite(if_node.children[6])
+            new_node = ast.If (test, suite, else_suite)
+            new_node.lineno = if_node.lineno
+            new_node.col_offset = if_node.col_offset
+            return new_node
         elif otherwise_string == "elif":
             elif_count = child_count - 4
-            after_elif = if_node.get_child(elif_count + 1)
+            after_elif = if_node.children[elif_count + 1]
             if after_elif.type == tokens.NAME and \
-                    after_elif.get_value() == "else":
+                    after_elif.value == "else":
                 has_else = True
                 elif_count -= 3
             else:
                 has_else = False
-            elif_count /= 4
+            elif_count //= 4
             if has_else:
-                last_elif = if_node.get_child(-6)
+                last_elif = if_node.children[-6]
                 last_elif_test = self.handle_expr(last_elif)
-                elif_body = self.handle_suite(if_node.get_child(-4))
-                else_body = self.handle_suite(if_node.get_child(-1))
-                otherwise = [ast.If(last_elif_test, elif_body, else_body,
-                                    last_elif.get_lineno(), last_elif.get_column())]
+                elif_body = self.handle_suite(if_node.children[-4])
+                else_body = self.handle_suite(if_node.children[-1])
+                new_node = ast.If(last_elif_test, elif_body, else_body)
+                new_node.lineno = last_elif.lineno
+                new_node.col_offset = last_elif.col_offset
+                otherwise = [new_node]
                 elif_count -= 1
             else:
-                otherwise = None
+                otherwise = []
             for i in range(elif_count):
                 offset = 5 + (elif_count - i - 1) * 4
-                elif_test_node = if_node.get_child(offset)
+                elif_test_node = if_node.children[offset]
                 elif_test = self.handle_expr(elif_test_node)
-                elif_body = self.handle_suite(if_node.get_child(offset + 2))
-                new_if = ast.If(elif_test, elif_body, otherwise,
-                                elif_test_node.get_lineno(), elif_test_node.get_column())
+                elif_body = self.handle_suite(if_node.children[offset + 2])
+                new_if = ast.If (elif_test, elif_body, otherwise)
+                new_if.lineno = elif_test_node.lineno
+                new_if.col_offset = elif_test_node.col_offset
                 otherwise = [new_if]
-            expr = self.handle_expr(if_node.get_child(1))
-            body = self.handle_suite(if_node.get_child(3))
-            return ast.If(expr, body, otherwise, if_node.get_lineno(), if_node.get_column())
+            expr = self.handle_expr(if_node.children[1])
+            body = self.handle_suite(if_node.children[3])
+            new_node = ast.If (expr, body, otherwise)
+            new_node.lineno = if_node.lineno
+            new_node.col_offset = if_node.col_offset
+            return new_node
         else:
             raise AssertionError("unknown if statement configuration")
 
     def handle_while_stmt(self, while_node):
-        loop_test = self.handle_expr(while_node.get_child(1))
-        body = self.handle_suite(while_node.get_child(3))
-        if while_node.num_children() == 7:
-            otherwise = self.handle_suite(while_node.get_child(6))
-        else:
-            otherwise = None
-        return ast.While(loop_test, body, otherwise, while_node.get_lineno(),
-                         while_node.get_column())
+        loop_test = self.handle_expr(while_node.children[1])
+        body = self.handle_suite(while_node.children[3])
+        if len(while_node.children) == 7:
+            otherwise = self.handle_suite(while_node.children[6])
+        else:
+            otherwise = []
+        new_node = ast.While (loop_test, body, otherwise)
+        new_node.lineno = while_node.lineno
+        new_node.col_offset = while_node.col_offset
+        return new_node
 
     def handle_for_stmt(self, for_node, is_async):
-        target_node = for_node.get_child(1)
-        target_as_exprlist = self.handle_exprlist(target_node, ast.Store)
-        if target_node.num_children() == 1:
+        target_node = for_node.children[1]
+        target_as_exprlist = self.handle_exprlist(target_node, ast.Store())
+        if len(target_node.children) == 1:
             target = target_as_exprlist[0]
         else:
-            target = ast.Tuple(target_as_exprlist, ast.Store,
-                               target_node.get_lineno(), target_node.get_column())
-        expr = self.handle_testlist(for_node.get_child(3))
-        body = self.handle_suite(for_node.get_child(5))
-        if for_node.num_children() == 9:
-            otherwise = self.handle_suite(for_node.get_child(8))
+            target = ast.Tuple(target_as_exprlist, ast.Store())
+            target.lineno = target_node.lineno
+            target.col_offset = target_node.col_offset
+        expr = self.handle_testlist(for_node.children[3])
+        body = self.handle_suite(for_node.children[5])
+        if len(for_node.children) == 9:
+            otherwise = self.handle_suite(for_node.children[8])
         else:
-            otherwise = None
+            otherwise = []
         if is_async:
-            return ast.AsyncFor(target, expr, body, otherwise, for_node.get_lineno(),
-                                for_node.get_column())
-        else:
-            return ast.For(target, expr, body, otherwise, for_node.get_lineno(),
-                           for_node.get_column())
+            new_node = ast.AsyncFor(target, expr, body, otherwise)
+            new_node.lineno = for_node.lineno
+            new_node.col_offset = for_node.col_offset
+            return new_node
+        else:
+            new_node = ast.For(target, expr, body, otherwise)
+            new_node.lineno = for_node.lineno
+            new_node.col_offset = for_node.col_offset
+            return new_node
 
     def handle_except_clause(self, exc, body):
         test = None
         name = None
         suite = self.handle_suite(body)
-        child_count = exc.num_children()
+        child_count = len(exc.children)
         if child_count >= 2:
-            test = self.handle_expr(exc.get_child(1))
+            test = self.handle_expr(exc.children[1])
         if child_count == 4:
-            name_node = exc.get_child(3)
-            name = self.new_identifier(name_node.get_value())
+            name_node = exc.children[3]
+            name = self.new_identifier(name_node.value)
             self.check_forbidden_name(name, name_node)
-        return ast.ExceptHandler(test, name, suite, exc.get_lineno(), exc.get_column())
+        new_node = ast.ExceptHandler (test, name, suite)
+        new_node.lineno = exc.lineno
+        new_node.col_offset = exc.col_offset
+        return new_node
 
     def handle_try_stmt(self, try_node):
-        body = self.handle_suite(try_node.get_child(2))
-        child_count = try_node.num_children()
+        body = self.handle_suite(try_node.children[2])
+        child_count = len(try_node.children)
         except_count = (child_count - 3 ) // 3
-        otherwise = None
-        finally_suite = None
-        possible_extra_clause = try_node.get_child(-3)
+        otherwise = []
+        finally_suite = []
+        possible_extra_clause = try_node.children[-3]
         if possible_extra_clause.type == tokens.NAME:
-            if possible_extra_clause.get_value() == "finally":
+            if possible_extra_clause.value == "finally":
                 if child_count >= 9 and \
-                        try_node.get_child(-6).type == tokens.NAME:
-                    otherwise = self.handle_suite(try_node.get_child(-4))
+                        try_node.children[-6].type == tokens.NAME:
+                    otherwise = self.handle_suite(try_node.children[-4])
                     except_count -= 1
-                finally_suite = self.handle_suite(try_node.get_child(-1))
+                finally_suite = self.handle_suite(try_node.children[-1])
                 except_count -= 1
             else:
-                otherwise = self.handle_suite(try_node.get_child(-1))
+                otherwise = self.handle_suite(try_node.children[-1])
                 except_count -= 1
         handlers = []
         if except_count:
             for i in range(except_count):
                 base_offset = i * 3
-                exc = try_node.get_child(3 + base_offset)
-                except_body = try_node.get_child(5 + base_offset)
+                exc = try_node.children[3 + base_offset]
+                except_body = try_node.children[5 + base_offset]
                 handlers.append(self.handle_except_clause(exc, except_body))
-        return ast.Try(body, handlers, otherwise, finally_suite,
-                       try_node.get_lineno(), try_node.get_column())
+        new_node = ast.Try (body, handlers, otherwise, finally_suite)
+        new_node.lineno = try_node.lineno
+        new_node.col_offset = try_node.col_offset
+        return new_node
+
+    def handle_with_stmt(self, with_node):
+        body = self.handle_suite(with_node.children[-1])
+        i = len(with_node.children) - 1
+        while True:
+            i -= 2
+            item = with_node.children[i]
+            test = self.handle_expr(item.children[0])
+            if len(item.children) == 3:
+                target = self.handle_expr(item.children[2])
+                self.set_context(target, ast.Store())
+            else:
+                target = None
+            wi = ast.With (test, target, body)
+            wi.lineno = with_node.lineno
+            wi.col_offset = with_node.col_offset
+            if i == 1:
+                break
+            body = [wi]
+        return wi
 
     def handle_with_item(self, item_node):
-        test = self.handle_expr(item_node.get_child(0))
-        if item_node.num_children() == 3:
-            target = self.handle_expr(item_node.get_child(2))
-            self.set_context(target, ast.Store)
+        test = self.handle_expr(item_node.children[0])
+        if len(item_node.children) == 3:
+            target = self.handle_expr(item_node.children[2])
+            self.set_context(target, ast.Store())
         else:
             target = None
         return ast.withitem(test, target)
 
     def handle_with_stmt(self, with_node, is_async):
-        body = self.handle_suite(with_node.get_child(-1))
-        items = [self.handle_with_item(with_node.get_child(i))
-                 for i in range(1, with_node.num_children()-2, 2)]
+        body = self.handle_suite(with_node.children[-1])
+        items = [self.handle_with_item(with_node.children[i])
+                 for i in range(1, len(with_node.children)-2, 2)]
         if is_async:
-            return ast.AsyncWith(items, body, with_node.get_lineno(),
-                                 with_node.get_column())
-        else:
-            return ast.With(items, body, with_node.get_lineno(),
-                            with_node.get_column())
+            new_node = ast.AsyncWith (items, body)
+            new_node.lineno = with_node.lineno
+            new_node.col_offset = with_node.col_offset
+            return new_node
+        else:
+            new_node = ast.With (items, body)
+            new_node.lineno = with_node.lineno
+            new_node.col_offset = with_node.col_offset
+            return new_node
 
     def handle_classdef(self, classdef_node, decorators=None):
-        name_node = classdef_node.get_child(1)
-        name = self.new_identifier(name_node.get_value())
+        if decorators is None:
+            decorators = []
+        name_node = classdef_node.children[1]
+        name = self.new_identifier(name_node.value)
         self.check_forbidden_name(name, name_node)
-        if classdef_node.num_children() == 4:
+        if len(classdef_node.children) == 4:
             # class NAME ':' suite
-            body = self.handle_suite(classdef_node.get_child(3))
-            return ast.ClassDef(name, None, None, body, decorators,
-                                classdef_node.get_lineno(), classdef_node.get_column())
-        if classdef_node.get_child(3).type == tokens.RPAR:
+            body = self.handle_suite(classdef_node.children[3])
+            new_node = ast.ClassDef (name, [], [], body, decorators)
+            new_node.lineno = classdef_node.lineno
+            new_node.col_offset = classdef_node.col_offset
+            return new_node
+        if classdef_node.children[3].type == tokens.RPAR:
             # class NAME '(' ')' ':' suite
-            body = self.handle_suite(classdef_node.get_child(5))
-            return ast.ClassDef(name, None, None, body, decorators,
-                                classdef_node.get_lineno(), classdef_node.get_column())
+            body = self.handle_suite(classdef_node.children[5])
+            new_node = ast.ClassDef (name, [], [], body, decorators)
+            new_node.lineno = classdef_node.lineno
+            new_node.col_offset = classdef_node.col_offset
+            return new_node
 
         # class NAME '(' arglist ')' ':' suite
         # build up a fake Call node so we can extract its pieces
-        call_name = ast.Name(name, ast.Load, classdef_node.get_lineno(),
-                             classdef_node.get_column())
-        call = self.handle_call(classdef_node.get_child(3), call_name)
-        body = self.handle_suite(classdef_node.get_child(6))
-        return ast.ClassDef(
-            name, call.args, call.keywords,
-            body, decorators, classdef_node.get_lineno(), classdef_node.get_column())
+        call_name = ast.Name (name, ast.Load())
+        call_name.lineno = classdef_node.lineno
+        call_name.col_offset = classdef_node.col_offset
+        call = self.handle_call(classdef_node.children[3], call_name)
+        body = self.handle_suite(classdef_node.children[6])
+        new_node = ast.ClassDef (name, call.args, call.keywords, body, decorators)
+        new_node.lineno = classdef_node.lineno
+        new_node.col_offset = classdef_node.col_offset
+        return new_node
 
     def handle_class_bases(self, bases_node):
-        if bases_node.num_children() == 1:
-            return [self.handle_expr(bases_node.get_child(0))]
+        if len(bases_node.children) == 1:
+            return [self.handle_expr(bases_node.children[0])]
         return self.get_expression_list(bases_node)
 
     def handle_funcdef_impl(self, funcdef_node, is_async, decorators=None):
-        name_node = funcdef_node.get_child(1)
-        name = self.new_identifier(name_node.get_value())
+        if decorators is None:
+            decorators = []
+        name_node = funcdef_node.children[1]
+        name = self.new_identifier(name_node.value)
         self.check_forbidden_name(name, name_node)
-        args = self.handle_arguments(funcdef_node.get_child(2))
+        args = self.handle_arguments(funcdef_node.children[2])
         suite = 4
         returns = None
-        if funcdef_node.get_child(3).type == tokens.RARROW:
-            returns = self.handle_expr(funcdef_node.get_child(4))
+        if funcdef_node.children[3].type == tokens.RARROW:
+            returns = self.handle_expr(funcdef_node.children[4])
             suite += 2
-        body = self.handle_suite(funcdef_node.get_child(suite))
+        body = self.handle_suite(funcdef_node.children[suite])
         if is_async:
-            return ast.AsyncFunctionDef(name, args, body, decorators, returns,
-                                        funcdef_node.get_lineno(), funcdef_node.get_column())
-        else:
-            return ast.FunctionDef(name, args, body, decorators, returns,
-                                   funcdef_node.get_lineno(), funcdef_node.get_column())
+            new_node = ast.AsyncFunctionDef (name, args, body, decorators,
+                                             returns)
+            new_node.lineno = funcdef_node.lineno
+            new_node.col_offset = funcdef_node.col_offset
+            return new_node
+        else:
+            new_node = ast.FunctionDef (name, args, body, decorators, returns)
+            new_node.lineno = funcdef_node.lineno
+            new_node.col_offset = funcdef_node.col_offset
+            return new_node
 
     def handle_async_funcdef(self, node, decorators=None):
-        return self.handle_funcdef_impl(node.get_child(1), 1, decorators)
-    
+        return self.handle_funcdef_impl(node.children[1], 1, decorators)
+
     def handle_funcdef(self, node, decorators=None):
         return self.handle_funcdef_impl(node, 0, decorators)
-    
+
     def handle_async_stmt(self, node):
-        ch = node.get_child(1)
         if ch.type == syms.funcdef:
             return self.handle_funcdef_impl(ch, 1)
         elif ch.type == syms.with_stmt:
@@ -511,8 +614,8 @@
             raise AssertionError("invalid async statement")
 
     def handle_decorated(self, decorated_node):
-        decorators = self.handle_decorators(decorated_node.get_child(0))
-        definition = decorated_node.get_child(1)
+        decorators = self.handle_decorators(decorated_node.children[0])
+        definition = decorated_node.children[1]
         if definition.type == syms.funcdef:
             node = self.handle_funcdef(definition, decorators)
         elif definition.type == syms.classdef:
@@ -521,55 +624,57 @@
             node = self.handle_async_funcdef(definition, decorators)
         else:
             raise AssertionError("unkown decorated")
-        node.lineno = decorated_node.get_lineno()
-        node.col_offset = decorated_node.get_column()
+        node.lineno = decorated_node.lineno
+        node.col_offset = decorated_node.col_offset
         return node
 
     def handle_decorators(self, decorators_node):
-        return [self.handle_decorator(decorators_node.get_child(i))
-                    for i in range(decorators_node.num_children())]
+        return [self.handle_decorator(dec) for dec in decorators_node.children]
 
     def handle_decorator(self, decorator_node):
-        dec_name = self.handle_dotted_name(decorator_node.get_child(1))
-        if decorator_node.num_children() == 3:
+        dec_name = self.handle_dotted_name(decorator_node.children[1])
+        if len(decorator_node.children) == 3:
             dec = dec_name
-        elif decorator_node.num_children() == 5:
-            dec = ast.Call(dec_name, None, None,
-                           decorator_node.get_lineno(), decorator_node.get_column())
+        elif len(decorator_node.children) == 5:
+            dec = ast.Call (dec_name, [], [])
+            dec.lineno = decorator_node.lineno
+            dec.col_offset = decorator_node.col_offset
         else:
-            dec = self.handle_call(decorator_node.get_child(3), dec_name)
+            dec = self.handle_call(decorator_node.children[3], dec_name)
         return dec
 
     def handle_dotted_name(self, dotted_name_node):
-        base_value = self.new_identifier(dotted_name_node.get_child(0).get_value())
-        name = ast.Name(base_value, ast.Load, dotted_name_node.get_lineno(),
-                        dotted_name_node.get_column())
-        for i in range(2, dotted_name_node.num_children(), 2):
-            attr = dotted_name_node.get_child(i).get_value()
+        base_value = self.new_identifier(dotted_name_node.children[0].value)
+        name = ast.Name (base_value, ast.Load())
+        name.lineno = dotted_name_node.lineno
+        name.col_offset = dotted_name_node.col_offset
+        for i in range(2, len(dotted_name_node.children), 2):
+            attr = dotted_name_node.children[i].value
             attr = self.new_identifier(attr)
-            name = ast.Attribute(name, attr, ast.Load, dotted_name_node.get_lineno(),
-                                 dotted_name_node.get_column())
+            name = ast.Attribute (name, attr, ast.Load())
+            name.lineno = dotted_name_node.lineno
+            name.col_offset = dotted_name_node.col_offset
         return name
 
     def handle_arguments(self, arguments_node):
         # This function handles both typedargslist (function definition)
         # and varargslist (lambda definition).
         if arguments_node.type == syms.parameters:
-            if arguments_node.num_children() == 2:
-                return ast.arguments(None, None, None, None, None, None)
-            arguments_node = arguments_node.get_child(1)
+            if len(arguments_node.children) == 2:
+                return ast.arguments([], None, [], [], None, [])
+            arguments_node = arguments_node.children[1]
         i = 0
-        child_count = arguments_node.num_children()
+        child_count = len(arguments_node.children)
         n_pos = 0
         n_pos_def = 0
         n_kwdonly = 0
         # scan args
         while i < child_count:
-            arg_type = arguments_node.get_child(i).type
+            arg_type = arguments_node.children[i].type
             if arg_type == tokens.STAR:
                 i += 1
                 if i < child_count:
-                    next_arg_type = arguments_node.get_child(i).type
+                    next_arg_type = arguments_node.children[i].type
                     if (next_arg_type == syms.tfpdef or
                         next_arg_type == syms.vfpdef):
                         i += 1
@@ -582,7 +687,7 @@
                 n_pos_def += 1
             i += 1
         while i < child_count:
-            arg_type = arguments_node.get_child(i).type
+            arg_type = arguments_node.children[i].type
             if arg_type == tokens.DOUBLESTAR:
                 break
             if arg_type == syms.vfpdef or arg_type == syms.tfpdef:
@@ -590,22 +695,24 @@
             i += 1
         pos = []
         posdefaults = []
-        kwonly = [] if n_kwdonly else None
+        kwonly = []
         kwdefaults = []
         kwarg = None
+        kwargann = None
         vararg = None
+        varargann = None
         if n_pos + n_kwdonly > 255:
             self.error("more than 255 arguments", arguments_node)
         # process args
         i = 0
         have_default = False
         while i < child_count:
-            arg = arguments_node.get_child(i)
+            arg = arguments_node.children[i]
             arg_type = arg.type
             if arg_type == syms.tfpdef or arg_type == syms.vfpdef:
                 if i + 1 < child_count and \
-                        arguments_node.get_child(i + 1).type == tokens.EQUAL:
-                    default_node = arguments_node.get_child(i + 2)
+                        arguments_node.children[i + 1].type == tokens.EQUAL:
+                    default_node = arguments_node.children[i + 2]
                     posdefaults.append(self.handle_expr(default_node))
                     i += 2
                     have_default = True
@@ -618,86 +725,101 @@
                 if i + 1 >= child_count:
                     self.error("named arguments must follow bare *",
                                arguments_node)
-                name_node = arguments_node.get_child(i + 1)
+                name_node = arguments_node.children[i + 1]
                 keywordonly_args = []
                 if name_node.type == tokens.COMMA:
                     i += 2
                     i = self.handle_keywordonly_args(arguments_node, i, kwonly,
                                                      kwdefaults)
                 else:
-                    vararg = self.handle_arg(name_node)
+                    vararg = name_node.children[0].value
+                    vararg = self.new_identifier(vararg)
+                    self.check_forbidden_name(vararg, name_node)
+                    if len(name_node.children) > 1:
+                        varargann = self.handle_expr(name_node.children[2])
                     i += 3
                     if i < child_count:
-                        next_arg_type = arguments_node.get_child(i).type
+                        next_arg_type = arguments_node.children[i].type
                         if (next_arg_type == syms.tfpdef or
                             next_arg_type == syms.vfpdef):
                             i = self.handle_keywordonly_args(arguments_node, i,
                                                              kwonly, kwdefaults)
             elif arg_type == tokens.DOUBLESTAR:
-                name_node = arguments_node.get_child(i + 1)
-                kwarg = self.handle_arg(name_node)
+                name_node = arguments_node.children[i + 1]
+                kwarg = name_node.children[0].value
+                kwarg = self.new_identifier(kwarg)
+                self.check_forbidden_name(kwarg, name_node)
+                if len(name_node.children) > 1:
+                    kwargann = self.handle_expr(name_node.children[2])
                 i += 3
             else:
                 raise AssertionError("unknown node in argument list")
-        return ast.arguments(pos, vararg, kwonly, kwdefaults, kwarg,
-                             posdefaults)
+        # TODO: fix annotations
+        # def __init__(self, args, vararg, varargannotation, kwonlyargs, kwarg, kwargannotation, defaults, kw_defaults):
+        # arguments(args=[arg(arg='a', annotation=None), arg(arg='b', annotation=None)],
+        #           vararg=arg(arg='more', annotation=None), kwonlyargs=[], kw_defaults=[],
+        #           kwarg=arg(arg='kmore', annotation=None), defaults=[Num(n=1)])
+        return ast.arguments(pos, vararg, kwonly, kwdefaults, kwarg, posdefaults)
 
     def handle_keywordonly_args(self, arguments_node, i, kwonly, kwdefaults):
         if kwonly is None:
             self.error("named arguments must follows bare *",
-                       arguments_node.get_child(i))
-        child_count = arguments_node.num_children()
+                       arguments_node.children[i])
+        child_count = len(arguments_node.children)
         while i < child_count:
-            arg = arguments_node.get_child(i)
+            arg = arguments_node.children[i]
             arg_type = arg.type
             if arg_type == syms.vfpdef or arg_type == syms.tfpdef:
                 if (i + 1 < child_count and
-                    arguments_node.get_child(i + 1).type == tokens.EQUAL):
-                    expr = self.handle_expr(arguments_node.get_child(i + 2))
+                    arguments_node.children[i + 1].type == tokens.EQUAL):
+                    expr = self.handle_expr(arguments_node.children[i + 2])
                     kwdefaults.append(expr)
                     i += 2
                 else:
                     kwdefaults.append(None)
                 ann = None
-                if arg.num_children() == 3:
-                    ann = self.handle_expr(arg.get_child(2))
-                name_node = arg.get_child(0)
-                argname = name_node.get_value()
+                if len(arg.children) == 3:
+                    ann = self.handle_expr(arg.children[2])
+                name_node = arg.children[0]
+                argname = name_node.value
                 argname = self.new_identifier(argname)
                 self.check_forbidden_name(argname, name_node)
-                kwonly.append(ast.arg(argname, ann, arg.get_lineno(),
-                                                    arg.get_column()))
+                kwonly.append(ast.arg(argname, ann))
                 i += 2
             elif arg_type == tokens.DOUBLESTAR:
                 return i
         return i
 
     def handle_arg(self, arg_node):
-        name_node = arg_node.get_child(0)
-        name = self.new_identifier(name_node.get_value())
+        name_node = arg_node.children[0]
+        name = self.new_identifier(name_node.value)
         self.check_forbidden_name(name, arg_node)
         ann = None
-        if arg_node.num_children() == 3:
-            ann = self.handle_expr(arg_node.get_child(2))
-        return ast.arg(name, ann, arg_node.get_lineno(), arg_node.get_column())
+        if len(arg_node.children) == 3:
+            ann = self.handle_expr(arg_node.children[2])
+        return ast.arg(name, ann)
 
     def handle_stmt(self, stmt):
+        # peel the onion a little bit
         stmt_type = stmt.type
         if stmt_type == syms.stmt:
-            stmt = stmt.get_child(0)
+            stmt = stmt.children[0]
             stmt_type = stmt.type
         if stmt_type == syms.simple_stmt:
-            stmt = stmt.get_child(0)
+            stmt = stmt.children[0]
             stmt_type = stmt.type
         if stmt_type == syms.small_stmt:
-            stmt = stmt.get_child(0)
+            stmt = stmt.children[0]
             stmt_type = stmt.type
             if stmt_type == syms.expr_stmt:
                 return self.handle_expr_stmt(stmt)
             elif stmt_type == syms.del_stmt:
                 return self.handle_del_stmt(stmt)
             elif stmt_type == syms.pass_stmt:
-                return ast.Pass(stmt.get_lineno(), stmt.get_column())
+                new_node = ast.Pass ()
+                new_node.lineno = stmt.lineno
+                new_node.col_offset = stmt.col_offset
+                return new_node
             elif stmt_type == syms.flow_stmt:
                 return self.handle_flow_stmt(stmt)
             elif stmt_type == syms.import_stmt:
@@ -711,18 +833,18 @@
             else:
                 raise AssertionError("unhandled small statement")
         elif stmt_type == syms.compound_stmt:
-            stmt = stmt.get_child(0)
+            stmt = stmt.children[0]
             stmt_type = stmt.type
             if stmt_type == syms.if_stmt:
                 return self.handle_if_stmt(stmt)
             elif stmt_type == syms.while_stmt:
                 return self.handle_while_stmt(stmt)
             elif stmt_type == syms.for_stmt:
-                return self.handle_for_stmt(stmt, 0)
+                return self.handle_for_stmt(stmt, False)
             elif stmt_type == syms.try_stmt:
                 return self.handle_try_stmt(stmt)
             elif stmt_type == syms.with_stmt:
-                return self.handle_with_stmt(stmt, 0)
+                return self.handle_with_stmt(stmt, False)
             elif stmt_type == syms.funcdef:
                 return self.handle_funcdef(stmt)
             elif stmt_type == syms.classdef:
@@ -737,95 +859,113 @@
             raise AssertionError("unknown statment type")
 
     def handle_expr_stmt(self, stmt):
-        if stmt.num_children() == 1:
-            expression = self.handle_testlist(stmt.get_child(0))
-            return ast.Expr(expression, stmt.get_lineno(), stmt.get_column())
-        elif stmt.get_child(1).type == syms.augassign:
+        if len(stmt.children) == 1:
+            expression = self.handle_testlist(stmt.children[0])
+            new_node = ast.Expr (expression)
+            new_node.lineno = stmt.lineno
+            new_node.col_offset = stmt.col_offset
+            return new_node
+        elif stmt.children[1].type == syms.augassign:
             # Augmented assignment.
-            target_child = stmt.get_child(0)
+            target_child = stmt.children[0]
             target_expr = self.handle_testlist(target_child)
-            self.set_context(target_expr, ast.Store)
-            value_child = stmt.get_child(2)
+            self.set_context(target_expr, ast.Store())
+            value_child = stmt.children[2]
             if value_child.type == syms.testlist:
                 value_expr = self.handle_testlist(value_child)
             else:
                 value_expr = self.handle_expr(value_child)
-            op_str = stmt.get_child(1).get_child(0).get_value()
+            op_str = stmt.children[1].children[0].value
             operator = augassign_operator_map[op_str]
-            return ast.AugAssign(target_expr, operator, value_expr,
-                                 stmt.get_lineno(), stmt.get_column())
+            new_node = ast.AugAssign (target_expr, operator(), value_expr)
+            new_node.lineno = stmt.lineno
+            new_node.col_offset = stmt.col_offset
+            return new_node
         else:
             # Normal assignment.
             targets = []
-            for i in range(0, stmt.num_children() - 2, 2):
-                target_node = stmt.get_child(i)
+            for i in range(0, len(stmt.children) - 2, 2):
+                target_node = stmt.children[i]
                 if target_node.type == syms.yield_expr:
                     self.error("assignment to yield expression not possible",
                                target_node)
                 target_expr = self.handle_testlist(target_node)
-                self.set_context(target_expr, ast.Store)
+                self.set_context(target_expr, ast.Store())
                 targets.append(target_expr)
-            value_child = stmt.get_child(-1)
+            value_child = stmt.children[-1]
             if value_child.type == syms.testlist_star_expr:
                 value_expr = self.handle_testlist(value_child)
             else:
                 value_expr = self.handle_expr(value_child)
-            return ast.Assign(targets, value_expr, stmt.get_lineno(), stmt.get_column())
+            new_node = ast.Assign (targets, value_expr)
+            new_node.lineno = stmt.lineno
+            new_node.col_offset = stmt.col_offset
+            return new_node
 
     def get_expression_list(self, tests):
-        return [self.handle_expr(tests.get_child(i))
-                for i in range(0, tests.num_children(), 2)]
+        return [self.handle_expr(tests.children[i])
+                for i in range(0, len(tests.children), 2)]
 
     def handle_testlist(self, tests):
-        if tests.num_children() == 1:
-            return self.handle_expr(tests.get_child(0))
+        if len(tests.children) == 1:
+            return self.handle_expr(tests.children[0])
         else:
             elts = self.get_expression_list(tests)
-            return ast.Tuple(elts, ast.Load, tests.get_lineno(), tests.get_column())
+            new_node = ast.Tuple (elts, ast.Load())
+            new_node.lineno = tests.lineno
+            new_node.col_offset = tests.col_offset
+            return new_node
 
     def handle_expr(self, expr_node):
         # Loop until we return something.
         while True:
             expr_node_type = expr_node.type
             if expr_node_type == syms.test or expr_node_type == syms.test_nocond:
-                first_child = expr_node.get_child(0)
+                first_child = expr_node.children[0]
                 if first_child.type in (syms.lambdef, syms.lambdef_nocond):
                     return self.handle_lambdef(first_child)
-                elif expr_node.num_children() > 1:
+                elif len(expr_node.children) > 1:
                     return self.handle_ifexp(expr_node)
                 else:
                     expr_node = first_child
             elif expr_node_type == syms.or_test or \
                     expr_node_type == syms.and_test:
-                if expr_node.num_children() == 1:
-                    expr_node = expr_node.get_child(0)
+                if len(expr_node.children) == 1:
+                    expr_node = expr_node.children[0]
                     continue
-                seq = [self.handle_expr(expr_node.get_child(i))
-                       for i in range(0, expr_node.num_children(), 2)]
+                seq = [self.handle_expr(expr_node.children[i])
+                       for i in range(0, len(expr_node.children), 2)]
                 if expr_node_type == syms.or_test:
                     op = ast.Or
                 else:
                     op = ast.And
-                return ast.BoolOp(op, seq, expr_node.get_lineno(), expr_node.get_column())
+                new_node = ast.BoolOp (op(), seq)
+                new_node.lineno = expr_node.lineno
+                new_node.col_offset = expr_node.col_offset
+                return new_node
             elif expr_node_type == syms.not_test:
-                if expr_node.num_children() == 1:
-                    expr_node = expr_node.get_child(0)
+                if len(expr_node.children) == 1:
+                    expr_node = expr_node.children[0]
                     continue
-                expr = self.handle_expr(expr_node.get_child(1))
-                return ast.UnaryOp(ast.Not, expr, expr_node.get_lineno(),
-                                   expr_node.get_column())
+                expr = self.handle_expr(expr_node.children[1])
+                new_node = ast.UnaryOp (ast.Not(), expr)
+                new_node.lineno = expr_node.lineno
+                new_node.col_offset = expr_node.col_offset
+                return new_node
             elif expr_node_type == syms.comparison:
-                if expr_node.num_children() == 1:
-                    expr_node = expr_node.get_child(0)
+                if len(expr_node.children) == 1:
+                    expr_node = expr_node.children[0]
                     continue
                 operators = []
                 operands = []
-                expr = self.handle_expr(expr_node.get_child(0))
-                for i in range(1, expr_node.num_children(), 2):
-                    operators.append(self.handle_comp_op(expr_node.get_child(i)))
-                    operands.append(self.handle_expr(expr_node.get_child(i + 1)))
-                return ast.Compare(expr, operators, operands, expr_node.get_lineno(),
-                                   expr_node.get_column())
+                expr = self.handle_expr(expr_node.children[0])
+                for i in range(1, len(expr_node.children), 2):
+                    operators.append(self.handle_comp_op(expr_node.children[i]))
+                    operands.append(self.handle_expr(expr_node.children[i + 1]))
+                new_node = ast.Compare (expr, operators, operands)
+                new_node.lineno = expr_node.lineno
+                new_node.col_offset = expr_node.col_offset
+                return new_node
             elif expr_node_type == syms.star_expr:
                 return self.handle_star_expr(expr_node)
             elif expr_node_type == syms.expr or \
@@ -834,27 +974,33 @@
                     expr_node_type == syms.shift_expr or \
                     expr_node_type == syms.arith_expr or \
                     expr_node_type == syms.term:
-                if expr_node.num_children() == 1:
-                    expr_node = expr_node.get_child(0)
+                if len(expr_node.children) == 1:
+                    expr_node = expr_node.children[0]
                     continue
                 return self.handle_binop(expr_node)
             elif expr_node_type == syms.yield_expr:
                 is_from = False
-                if expr_node.num_children() > 1:
-                    arg_node = expr_node.get_child(1)  # yield arg
-                    if arg_node.num_children() == 2:
+                if len(expr_node.children) > 1:
+                    arg_node = expr_node.children[1]  # yield arg
+                    if len(arg_node.children) == 2:
                         is_from = True
-                        expr = self.handle_expr(arg_node.get_child(1))
+                        expr = self.handle_expr(arg_node.children[1])
                     else:
-                        expr = self.handle_testlist(arg_node.get_child(0))
+                        expr = self.handle_testlist(arg_node.children[0])
                 else:
                     expr = None
                 if is_from:
-                    return ast.YieldFrom(expr, expr_node.get_lineno(), expr_node.get_column())
-                return ast.Yield(expr, expr_node.get_lineno(), expr_node.get_column())
+                    new_node = ast.YieldFrom (expr)
+                    new_node.lineno = expr_node.lineno
+                    new_node.col_offset = expr_node.col_offset
+                    return new_node
+                new_node = ast.Yield (expr)
+                new_node.lineno = expr_node.lineno
+                new_node.col_offset = expr_node.col_offset
+                return new_node
             elif expr_node_type == syms.factor:
-                if expr_node.num_children() == 1:
-                    expr_node = expr_node.get_child(0)
+                if len(expr_node.children) == 1:
+                    expr_node = expr_node.children[0]
                     continue
                 return self.handle_factor(expr_node)
             elif expr_node_type == syms.power:
@@ -863,82 +1009,90 @@
                 raise AssertionError("unknown expr")
 
     def handle_star_expr(self, star_expr_node):
-        expr = self.handle_expr(star_expr_node.get_child(1))
-        return ast.Starred(expr, ast.Load, star_expr_node.get_lineno(),
-                           star_expr_node.get_column())
+        expr = self.handle_expr(star_expr_node.children[1])
+        new_node = ast.Starred (expr, ast.Load())
+        new_node.lineno = star_expr_node.lineno
+        new_node.col_offset = star_expr_node.col_offset
+        return new_node
 
     def handle_lambdef(self, lambdef_node):
-        expr = self.handle_expr(lambdef_node.get_child(-1))
-        if lambdef_node.num_children() == 3:
-            args = ast.arguments(None, None, None, None, None, None)
-        else:
-            args = self.handle_arguments(lambdef_node.get_child(1))
-        return ast.Lambda(args, expr, lambdef_node.get_lineno(), lambdef_node.get_column())
+        expr = self.handle_expr(lambdef_node.children[-1])
+        if len(lambdef_node.children) == 3:
+            args = ast.arguments([], None, [], [], None, [])
+        else:
+            args = self.handle_arguments(lambdef_node.children[1])
+        new_node = ast.Lambda (args, expr)
+        new_node.lineno = lambdef_node.lineno
+        new_node.col_offset = lambdef_node.col_offset
+        return new_node
 
     def handle_ifexp(self, if_expr_node):
-        body = self.handle_expr(if_expr_node.get_child(0))
-        expression = self.handle_expr(if_expr_node.get_child(2))
-        otherwise = self.handle_expr(if_expr_node.get_child(4))
-        return ast.IfExp(expression, body, otherwise, if_expr_node.get_lineno(),
-                         if_expr_node.get_column())
+        body = self.handle_expr(if_expr_node.children[0])
+        expression = self.handle_expr(if_expr_node.children[2])
+        otherwise = self.handle_expr(if_expr_node.children[4])
+        new_node = ast.IfExp (expression, body, otherwise)
+        new_node.lineno = if_expr_node.lineno
+        new_node.col_offset = if_expr_node.col_offset
+        return new_node
 
     def handle_comp_op(self, comp_op_node):
-        comp_node = comp_op_node.get_child(0)
+        comp_node = comp_op_node.children[0]
         comp_type = comp_node.type
-        if comp_op_node.num_children() == 1:
+        if len(comp_op_node.children) == 1:
             if comp_type == tokens.LESS:
-                return ast.Lt
+                return ast.Lt()
             elif comp_type == tokens.GREATER:
-                return ast.Gt
+                return ast.Gt()
             elif comp_type == tokens.EQEQUAL:
-                return ast.Eq
+                return ast.Eq()
             elif comp_type == tokens.LESSEQUAL:
-                return ast.LtE
+                return ast.LtE()
             elif comp_type == tokens.GREATEREQUAL:
-                return ast.GtE
+                return ast.GtE()
             elif comp_type == tokens.NOTEQUAL:
                 flufl = self.compile_info.flags & consts.CO_FUTURE_BARRY_AS_BDFL
-                if flufl and comp_node.get_value() == '!=':
+                if flufl and comp_node.value == '!=':
                     self.error('invalid comparison', comp_node)
-                elif not flufl and comp_node.get_value() == '<>':
+                elif not flufl and comp_node.value == '<>':
                     self.error('invalid comparison', comp_node)
-                return ast.NotEq
+                return ast.NotEq()
             elif comp_type == tokens.NAME:
-                if comp_node.get_value() == "is":
-                    return ast.Is
-                elif comp_node.get_value() == "in":
-                    return ast.In
+                if comp_node.value == "is":
+                    return ast.Is()
+                elif comp_node.value == "in":
+                    return ast.In()
                 else:
                     raise AssertionError("invalid comparison")
             else:
                 raise AssertionError("invalid comparison")
         else:
-            if comp_op_node.get_child(1).get_value() == "in":
-                return ast.NotIn
-            elif comp_node.get_value() == "is":
-                return ast.IsNot
+            if comp_op_node.children[1].value == "in":
+                return ast.NotIn()
+            elif comp_node.value == "is":
+                return ast.IsNot()
             else:
                 raise AssertionError("invalid comparison")
 
     def handle_binop(self, binop_node):
-        left = self.handle_expr(binop_node.get_child(0))
-        right = self.handle_expr(binop_node.get_child(2))
-        op = operator_map(binop_node.get_child(1).type)
-        result = ast.BinOp(left, op, right, binop_node.get_lineno(),
-                           binop_node.get_column())
-        number_of_ops = (binop_node.num_children() - 1) / 2
+        left = self.handle_expr(binop_node.children[0])
+        right = self.handle_expr(binop_node.children[2])
+        op = operator_map(binop_node.children[1].type)
+        result = ast.BinOp (left, op(), right)
+        result.lineno = binop_node.lineno
+        result.col_offset = binop_node.col_offset
+        number_of_ops = (len(binop_node.children) - 1) // 2
         for i in range(1, number_of_ops):
-            op_node = binop_node.get_child(i * 2 + 1)
+            op_node = binop_node.children[i * 2 + 1]
             op = operator_map(op_node.type)
-            sub_right = self.handle_expr(binop_node.get_child(i * 2 + 2))
-            result = ast.BinOp(result, op, sub_right, op_node.get_lineno(),
-                               op_node.get_column())
+            sub_right = self.handle_expr(binop_node.children[i * 2 + 2])
+            result = ast.BinOp (result, op(), sub_right)
+            result.lineno = op_node.lineno
+            result.col_offset = op_node.col_offset
         return result
 
     def handle_factor(self, factor_node):
-        from pypy.interpreter.pyparser.parser import Terminal
-        expr = self.handle_expr(factor_node.get_child(1))
-        op_type = factor_node.get_child(0).type
+        expr = self.handle_expr(factor_node.children[1])
+        op_type = factor_node.children[0].type
         if op_type == tokens.PLUS:
             op = ast.UAdd
         elif op_type == tokens.MINUS:
@@ -947,21 +1101,26 @@
             op = ast.Invert
         else:
             raise AssertionError("invalid factor node")
-        return ast.UnaryOp(op, expr, factor_node.get_lineno(), factor_node.get_column())
+        new_node = ast.UnaryOp (op(), expr)
+        new_node.lineno = factor_node.lineno
+        new_node.col_offset = factor_node.col_offset
+        return new_node
 
     def handle_atom_expr(self, atom_node):
         start = 0
-        num_ch = atom_node.num_children()
-        if atom_node.get_child(0).type == tokens.AWAIT:
+        num_ch = len(atom_node.children)
+        if atom_node.children[0].type == tokens.AWAIT:
             start = 1
-        atom_expr = self.handle_atom(atom_node.get_child(start))
+        atom_expr = self.handle_atom(atom_node.children[start])
         if num_ch == 1:
             return atom_expr
         if start and num_ch == 2:
-            return ast.Await(atom_expr, atom_node.get_lineno(),
-                             atom_node.get_column())
-        for i in range(start+1, num_ch):
-            trailer = atom_node.get_child(i)
+            new_node = ast.Await(atom_expr)
+            new_node.lineno = atom_node.lineno
+            new_node.col_offset = atom_node.col_offset
+            return new_node
+        for i in range(1, num_ch):
+            trailer = atom_node.children[i]
             if trailer.type != syms.trailer:
                 break
             tmp_atom_expr = self.handle_trailer(trailer, atom_expr)
@@ -969,24 +1128,27 @@
             tmp_atom_expr.col_offset = atom_expr.col_offset
             atom_expr = tmp_atom_expr
         if start:
-            return ast.Await(atom_expr, atom_node.get_lineno(),
-                             atom_node.get_column())
+            new_node = ast.Await(atom_expr)
+            new_node.lineno = atom_node.lineno
+            new_node.col_offset = atom_node.col_offset
+            return new_node
         else:
             return atom_expr
-    
+
     def handle_power(self, power_node):
-        atom_expr = self.handle_atom_expr(power_node.get_child(0))
-        if power_node.num_children() == 1:
+        atom_expr = self.handle_atom_expr(power_node.children[0])
+        if len(power_node.children) == 1:
             return atom_expr
-        if power_node.get_child(-1).type == syms.factor:
-            right = self.handle_expr(power_node.get_child(-1))
-            atom_expr = ast.BinOp(atom_expr, ast.Pow, right, power_node.get_lineno(),
-                                  power_node.get_column())
+        if power_node.children[-1].type == syms.factor:
+            right = self.handle_expr(power_node.children[-1])
+            atom_expr = ast.BinOp (atom_expr, ast.Pow(), right)
+            atom_expr.lineno = power_node.lineno
+            atom_expr.col_offset = power_node.col_offset
         return atom_expr
 
     def handle_slice(self, slice_node):
-        first_child = slice_node.get_child(0)
-        if slice_node.num_children() == 1 and first_child.type == syms.test:
+        first_child = slice_node.children[0]
+        if len(slice_node.children) == 1 and first_child.type == syms.test:
             index = self.handle_expr(first_child)
             return ast.Index(index)
         lower = None
@@ -995,74 +1157,85 @@
         if first_child.type == syms.test:
             lower = self.handle_expr(first_child)
         if first_child.type == tokens.COLON:
-            if slice_node.num_children() > 1:
-                second_child = slice_node.get_child(1)
+            if len(slice_node.children) > 1:
+                second_child = slice_node.children[1]
                 if second_child.type == syms.test:
                     upper = self.handle_expr(second_child)
-        elif slice_node.num_children() > 2:
-            third_child = slice_node.get_child(2)
+        elif len(slice_node.children) > 2:
+            third_child = slice_node.children[2]
             if third_child.type == syms.test:
                 upper = self.handle_expr(third_child)
-        last_child = slice_node.get_child(-1)
+        last_child = slice_node.children[-1]
         if last_child.type == syms.sliceop:
-            if last_child.num_children() != 1:
-                step_child = last_child.get_child(1)
+            if len(last_child.children) != 1:
+                step_child = last_child.children[1]
                 if step_child.type == syms.test:
                     step = self.handle_expr(step_child)
         return ast.Slice(lower, upper, step)
 
     def handle_trailer(self, trailer_node, left_expr):
-        first_child = trailer_node.get_child(0)
+        first_child = trailer_node.children[0]
         if first_child.type == tokens.LPAR:
-            if trailer_node.num_children() == 2:
-                return ast.Call(left_expr, None, None,
-                                trailer_node.get_lineno(), trailer_node.get_column())
+            if len(trailer_node.children) == 2:
+                new_node = ast.Call (left_expr, [], [])
+                new_node.lineno = trailer_node.lineno
+                new_node.col_offset = trailer_node.col_offset
+                return new_node
             else:
-                return self.handle_call(trailer_node.get_child(1), left_expr)
+                return self.handle_call(trailer_node.children[1], left_expr)
         elif first_child.type == tokens.DOT:
-            attr = self.new_identifier(trailer_node.get_child(1).get_value())
-            return ast.Attribute(left_expr, attr, ast.Load,
-                                 trailer_node.get_lineno(), trailer_node.get_column())
-        else:
-            middle = trailer_node.get_child(1)
-            if middle.num_children() == 1:
-                slice = self.handle_slice(middle.get_child(0))
-                return ast.Subscript(left_expr, slice, ast.Load,
-                                     middle.get_lineno(), middle.get_column())
+            attr = self.new_identifier(trailer_node.children[1].value)
+            new_node = ast.Attribute (left_expr, attr, ast.Load())
+            new_node.lineno = trailer_node.lineno
+            new_node.col_offset = trailer_node.col_offset
+            return new_node
+        else:
+            middle = trailer_node.children[1]
+            if len(middle.children) == 1:
+                slice = self.handle_slice(middle.children[0])
+                new_node = ast.Subscript (left_expr, slice, ast.Load())
+                new_node.lineno = middle.lineno
+                new_node.col_offset = middle.col_offset
+                return new_node
             slices = []
             simple = True
-            for i in range(0, middle.num_children(), 2):
-                slc = self.handle_slice(middle.get_child(i))
+            for i in range(0, len(middle.children), 2):
+                slc = self.handle_slice(middle.children[i])
                 if not isinstance(slc, ast.Index):
                     simple = False
                 slices.append(slc)
             if not simple:
                 ext_slice = ast.ExtSlice(slices)
-                return ast.Subscript(left_expr, ext_slice, ast.Load,
-                                     middle.get_lineno(), middle.get_column())
+                new_node = ast.Subscript (left_expr, ext_slice, ast.Load())
+                new_node.lineno = middle.lineno
+                new_node.col_offset = middle.col_offset
+                return new_node
             elts = []
             for idx in slices:
                 assert isinstance(idx, ast.Index)
                 elts.append(idx.value)
-            tup = ast.Tuple(elts, ast.Load, middle.get_lineno(), middle.get_column())
-            return ast.Subscript(left_expr, ast.Index(tup), ast.Load,
-                                 middle.get_lineno(), middle.get_column())
+            tup = ast.Tuple (elts, ast.Load())
+            tup.lineno = middle.lineno
+            tup.col_offset = middle.col_offset
+            new_node = ast.Subscript(left_expr, ast.Index (tup), ast.Load())
+            new_node.lineno = middle.lineno
+            new_node.col_offset = middle.col_offset
+            return new_node
 
     def handle_call(self, args_node, callable_expr):
         arg_count = 0 # position args + iterable args unpackings
         keyword_count = 0 # keyword args + keyword args unpackings
-        generator_count = 0 
-        for i in range(args_node.num_children()):
-            argument = args_node.get_child(i)
+        generator_count = 0
+        for argument in args_node.children:
             if argument.type == syms.argument:
-                if argument.num_children() == 1:
+                if len(argument.children) == 1:
                     arg_count += 1
-                elif argument.get_child(1).type == syms.comp_for:
+                elif argument.children[1].type == syms.comp_for:
                     generator_count += 1
-                elif argument.get_child(0).type == tokens.STAR:
+                elif argument.children[0].type == tokens.STAR:
                     arg_count += 1
                 else:
-                    # argument.get_child(0).type == tokens.DOUBLESTAR
+                    # argument.children[0].type == tokens.DOUBLESTAR
                     # or keyword arg
                     keyword_count += 1
         if generator_count > 1 or \
@@ -1075,13 +1248,13 @@
         keywords = []
         used_keywords = {}
         doublestars_count = 0 # just keyword argument unpackings
-        child_count = args_node.num_children()
+        child_count = len(args_node.children)
         i = 0
         while i < child_count:
-            argument = args_node.get_child(i)
+            argument = args_node.children[i]
             if argument.type == syms.argument:
-                expr_node = argument.get_child(0)
-                if argument.num_children() == 1:
+                expr_node = argument.children[0]
+                if len(argument.children) == 1:
                     # a positional argument
                     if keywords:
                         if doublestars_count:
@@ -1099,17 +1272,18 @@
                         self.error("iterable argument unpacking follows "
                                    "keyword argument unpacking",
                                    expr_node)
-                    expr = self.handle_expr(argument.get_child(1))
-                    args.append(ast.Starred(expr, ast.Load,
-                                            expr_node.get_lineno(),
-                                            expr_node.get_column()))
+                    expr = self.handle_expr(argument.children[1])
+                    new_node = ast.Starred(expr, ast.Load())
+                    new_node.lineno = expr_node.lineno
+                    new_node.col_offset = expr_node.col_offset
+                    args.append(new_node)
                 elif expr_node.type == tokens.DOUBLESTAR:
                     # a keyword argument unpacking
                     i += 1
-                    expr = self.handle_expr(argument.get_child(1))
+                    expr = self.handle_expr(argument.children[1])
                     keywords.append(ast.keyword(None, expr))
                     doublestars_count += 1
-                elif argument.get_child(1).type == syms.comp_for:
+                elif argument.children[1].type == syms.comp_for:
                     # the lone generator expression
                     args.append(self.handle_genexp(argument))
                 else:
@@ -1126,140 +1300,119 @@
                         self.error("keyword argument repeated", expr_node)
                     used_keywords[keyword] = None
                     self.check_forbidden_name(keyword, expr_node)
-                    keyword_value = self.handle_expr(argument.get_child(2))
+                    keyword_value = self.handle_expr(argument.children[2])
                     keywords.append(ast.keyword(keyword, keyword_value))
             i += 1
         if not args:
-            args = None
+            args = []
         if not keywords:
-            keywords = None
-        return ast.Call(callable_expr, args, keywords, callable_expr.lineno,
-                        callable_expr.col_offset)
+            keywords = []
+        new_node = ast.Call(callable_expr, args, keywords)
+        new_node.lineno = callable_expr.lineno
+        new_node.col_offset = callable_expr.col_offset
+        return new_node
 
     def parse_number(self, raw):
-        base = 10
-        if raw.startswith("-"):
-            negative = True
-            raw = raw.lstrip("-")
-        else:
-            negative = False
-        if raw.startswith("0"):
-            if len(raw) > 2 and raw[1] in "Xx":
-                base = 16
-            elif len(raw) > 2 and raw[1] in "Bb":
-                base = 2
-            ## elif len(raw) > 2 and raw[1] in "Oo": # Fallback below is enough
-            ##     base = 8
-            elif len(raw) > 1:
-                base = 8
-            # strip leading characters
-            i = 0
-            limit = len(raw) - 1
-            while i < limit:
-                if base == 16 and raw[i] not in "0xX":
-                    break
-                if base == 8 and raw[i] not in "0oO":
-                    break
-                if base == 2 and raw[i] not in "0bB":
-                    break
-                i += 1
-            raw = raw[i:]
-            if not raw[0].isdigit():
-                raw = "0" + raw
-        if negative:
-            raw = "-" + raw
-        w_num_str = self.space.newtext(raw)
-        w_base = self.space.newint(base)
-        if raw[-1] in "jJ":
-            tp = self.space.w_complex
-            return self.space.call_function(tp, w_num_str)
-        try:
-            return self.space.call_function(self.space.w_int, w_num_str, w_base)
-        except error.OperationError as e:
-            if not e.match(self.space, self.space.w_ValueError):
-                raise
-            return self.space.call_function(self.space.w_float, w_num_str)
+        return eval(raw)
 
-    @always_inline
     def handle_dictelement(self, node, i):
-        if node.get_child(i).type == tokens.DOUBLESTAR:
+        if node.children[i].type == tokens.DOUBLESTAR:
             key = None
-            value = self.handle_expr(node.get_child(i+1))
+            value = self.handle_expr(node.children[i+1])
             i += 2
         else:
-            key = self.handle_expr(node.get_child(i))
-            value = self.handle_expr(node.get_child(i+2))
+            key = self.handle_expr(node.children[i])
+            value = self.handle_expr(node.children[i+2])
             i += 3
         return (i,key,value)
 
     def handle_atom(self, atom_node):
-        first_child = atom_node.get_child(0)
+        first_child = atom_node.children[0]
         first_child_type = first_child.type
         if first_child_type == tokens.NAME:
-            name = first_child.get_value()
+            name = first_child.value
             if name == "None":
-                w_singleton = self.space.w_None
+                w_singleton = None
             elif name == "True":
-                w_singleton = self.space.w_True
+                w_singleton = True
             elif name == "False":
-                w_singleton = self.space.w_False
+                w_singleton = False
             else:
                 name = self.new_identifier(name)
-                return ast.Name(name, ast.Load, first_child.get_lineno(),
-                                first_child.get_column())
-            return ast.NameConstant(w_singleton, first_child.get_lineno(),
-                                first_child.get_column())
+                new_node = ast.Name(name, ast.Load())
+                new_node.lineno = first_child.lineno
+                new_node.col_offset = first_child.col_offset
+                return new_node
+            new_node = ast.NameConstant(w_singleton)
+            new_node.lineno = first_child.lineno
+            new_node.col_offset = first_child.col_offset
+            return new_node
         #
         elif first_child_type == tokens.STRING:
             return fstring.string_parse_literal(self, atom_node)
         #
         elif first_child_type == tokens.NUMBER:
-            num_value = self.parse_number(first_child.get_value())
-            return ast.Num(num_value, atom_node.get_lineno(), atom_node.get_column())
+            num_value = self.parse_number(first_child.value)
+            new_node = ast.Num(num_value)
+            new_node.lineno = atom_node.lineno
+            new_node.col_offset = atom_node.col_offset
+            return new_node
         elif first_child_type == tokens.ELLIPSIS:
-            return ast.Ellipsis(atom_node.get_lineno(), atom_node.get_column())
+            new_node = ast.Ellipsis()
+            new_node.lineno = atom_node.lineno
+            new_node.col_offset = atom_node.col_offset
+            return new_node
         elif first_child_type == tokens.LPAR:
-            second_child = atom_node.get_child(1)
+            second_child = atom_node.children[1]
             if second_child.type == tokens.RPAR:
-                return ast.Tuple(None, ast.Load, atom_node.get_lineno(),
-                                 atom_node.get_column())
+                new_node = ast.Tuple(None, ast.Load())
+                new_node.lineno = atom_node.lineno
+                new_node.col_offset = atom_node.col_offset
+                return new_node
             elif second_child.type == syms.yield_expr:
                 return self.handle_expr(second_child)
             return self.handle_testlist_gexp(second_child)
         elif first_child_type == tokens.LSQB:
-            second_child = atom_node.get_child(1)
+            second_child = atom_node.children[1]
             if second_child.type == tokens.RSQB:
-                return ast.List(None, ast.Load, atom_node.get_lineno(),
-                                atom_node.get_column())
-            if second_child.num_children() == 1 or \
-                    second_child.get_child(1).type == tokens.COMMA:
+                new_node = ast.List([], ast.Load())
+                new_node.lineno = atom_node.lineno
+                new_node.col_offset = atom_node.col_offset
+                return new_node
+            if len(second_child.children) == 1 or \
+                    second_child.children[1].type == tokens.COMMA:
                 elts = self.get_expression_list(second_child)
-                return ast.List(elts, ast.Load, atom_node.get_lineno(),
-                                atom_node.get_column())
+                new_node = ast.List(elts, ast.Load())
+                new_node.lineno = atom_node.lineno
+                new_node.col_offset = atom_node.col_offset
+                return new_node
             return self.handle_listcomp(second_child)
         elif first_child_type == tokens.LBRACE:
-            maker = atom_node.get_child(1)
-            n_maker_children = maker.num_children()
+            maker = atom_node.children[1]
+            n_maker_children = len(maker.children)
             if maker.type == tokens.RBRACE:
                 # an empty dict
-                return ast.Dict(None, None, atom_node.get_lineno(), atom_node.get_column())
+                new_node = ast.Dict(None, None)
+                new_node.lineno = atom_node.lineno
+                new_node.col_offset = atom_node.col_offset
+                return new_node
             else:
-                is_dict = maker.get_child(0).type == tokens.DOUBLESTAR
+                is_dict = maker.children[0].type == tokens.DOUBLESTAR
                 if (n_maker_children == 1 or
                     (n_maker_children > 1 and
-                     maker.get_child(1).type == tokens.COMMA)):
+                     maker.children[1].type == tokens.COMMA)):
                     # a set display
                     return self.handle_setdisplay(maker, atom_node)
-                elif n_maker_children > 1 and maker.get_child(1).type == syms.comp_for:
+                elif n_maker_children > 1 and maker.children[1].type == syms.comp_for:
                     # a set comprehension
                     return self.handle_setcomp(maker, atom_node)
                 elif (n_maker_children > (3-is_dict) and
-                      maker.get_child(3-is_dict).type == syms.comp_for):
+                      maker.children[3-is_dict].type == syms.comp_for):
                     # a dictionary comprehension
                     if is_dict:
                         raise self.error("dict unpacking cannot be used in "
                                          "dict comprehension", atom_node)
-                    
+
                     return self.handle_dictcomp(maker, atom_node)
                 else:
                     # a dictionary display
@@ -1268,8 +1421,8 @@
             raise AssertionError("unknown atom")
 
     def handle_testlist_gexp(self, gexp_node):
-        if gexp_node.num_children() > 1 and \
-                gexp_node.get_child(1).type == syms.comp_for:
+        if len(gexp_node.children) > 1 and \
+                gexp_node.children[1].type == syms.comp_for:
             return self.handle_genexp(gexp_node)
         return self.handle_testlist(gexp_node)
 
@@ -1278,18 +1431,18 @@
         current_for = comp_node
         while True:
             count += 1
-            if current_for.num_children() == 5:
-                current_iter = current_for.get_child(4)
+            if len(current_for.children) == 5:
+                current_iter = current_for.children[4]
             else:
                 return count
             while True:
-                first_child = current_iter.get_child(0)
+                first_child = current_iter.children[0]
                 if first_child.type == syms.comp_for:
-                    current_for = current_iter.get_child(0)
+                    current_for = current_iter.children[0]
                     break
                 elif first_child.type == syms.comp_if:
-                    if first_child.num_children() == 3:
-                        current_iter = first_child.get_child(2)
+                    if len(first_child.children) == 3:
+                        current_iter = first_child.children[2]
                     else:
                         return count
                 else:
@@ -1298,24 +1451,24 @@
     def count_comp_ifs(self, iter_node):
         count = 0
         while True:
-            first_child = iter_node.get_child(0)
+            first_child = iter_node.children[0]
             if first_child.type == syms.comp_for:
                 return count
             count += 1
-            if first_child.num_children() == 2:
+            if len(first_child.children) == 2:
                 return count
-            iter_node = first_child.get_child(2)
+            iter_node = first_child.children[2]
 
     def comprehension_helper(self, comp_node):
         fors_count = self.count_comp_fors(comp_node)
         comps = []
         for i in range(fors_count):
-            for_node = comp_node.get_child(1)
-            for_targets = self.handle_exprlist(for_node, ast.Store)
-            expr = self.handle_expr(comp_node.get_child(3))
+            for_node = comp_node.children[1]
+            for_targets = self.handle_exprlist(for_node, ast.Store())
+            expr = self.handle_expr(comp_node.children[3])
             assert isinstance(expr, ast.expr)
-            if for_node.num_children() == 1:
-                comp = ast.comprehension(for_targets[0], expr, None)
+            if len(for_node.children) == 1:
+                comp = ast.comprehension(for_targets[0], expr, [])
             else:
                 # Modified in python2.7, see http://bugs.python.org/issue6704
                 # Fixing unamed tuple location
@@ -1323,85 +1476,63 @@
                 assert isinstance(expr_node, ast.expr)
                 col = expr_node.col_offset
                 line = expr_node.lineno
-                target = ast.Tuple(for_targets, ast.Store, line, col)
-                comp = ast.comprehension(target, expr, None)
-            if comp_node.num_children() == 5:
-                comp_node = comp_iter = comp_node.get_child(4)
+                target = ast.Tuple(for_targets, ast.Store(), line, col)
+                comp = ast.comprehension(target, expr, [])
+            if len(comp_node.children) == 5:
+                comp_node = comp_iter = comp_node.children[4]
                 assert comp_iter.type == syms.comp_iter
                 ifs_count = self.count_comp_ifs(comp_iter)
                 if ifs_count:
                     ifs = []
                     for j in range(ifs_count):
-                        comp_node = comp_if = comp_iter.get_child(0)
-                        ifs.append(self.handle_expr(comp_if.get_child(1)))
-                        if comp_if.num_children() == 3:
-                            comp_node = comp_iter = comp_if.get_child(2)
+                        comp_node = comp_if = comp_iter.children[0]
+                        ifs.append(self.handle_expr(comp_if.children[1]))
+                        if len(comp_if.children) == 3:
+                            comp_node = comp_iter = comp_if.children[2]
                     comp.ifs = ifs
                 if comp_node.type == syms.comp_iter:
-                    comp_node = comp_node.get_child(0)
+                    comp_node = comp_node.children[0]
             assert isinstance(comp, ast.comprehension)
             comps.append(comp)
         return comps
 
     def handle_genexp(self, genexp_node):
-        ch = genexp_node.get_child(0)
-        elt = self.handle_expr(ch)
-        if isinstance(elt, ast.Starred):
-            self.error("iterable unpacking cannot be used in comprehension", ch)
-        comps = self.comprehension_helper(genexp_node.get_child(1))
-        return ast.GeneratorExp(elt, comps, genexp_node.get_lineno(),
-                                genexp_node.get_column())
+        elt = self.handle_expr(genexp_node.children[0])
+        comps = self.comprehension_helper(genexp_node.children[1])
+        new_node = ast.GeneratorExp (elt, comps)
+        new_node.lineno = genexp_node.lineno
+        new_node.col_offset = genexp_node.col_offset
+        return new_node
 
     def handle_listcomp(self, listcomp_node):
-        ch = listcomp_node.get_child(0)
-        elt = self.handle_expr(ch)
-        if isinstance(elt, ast.Starred):
-            self.error("iterable unpacking cannot be used in comprehension", ch)
-        comps = self.comprehension_helper(listcomp_node.get_child(1))
-        return ast.ListComp(elt, comps, listcomp_node.get_lineno(),
-                            listcomp_node.get_column())
-
-    def handle_setcomp(self, set_maker, atom_node):
-        ch = set_maker.get_child(0)
-        elt = self.handle_expr(ch)
-        if isinstance(elt, ast.Starred):
-            self.error("iterable unpacking cannot be used in comprehension", ch)
-        comps = self.comprehension_helper(set_maker.get_child(1))
-        return ast.SetComp(elt, comps, atom_node.get_lineno(),
-                                       atom_node.get_column())
-
-    def handle_dictcomp(self, dict_maker, atom_node):
-        i, key, value = self.handle_dictelement(dict_maker, 0)
-        comps = self.comprehension_helper(dict_maker.get_child(i))
-        return ast.DictComp(key, value, comps, atom_node.get_lineno(),
-                                               atom_node.get_column())
-    
-    def handle_dictdisplay(self, node, atom_node):
-        keys = []
-        values = []
-        i = 0
-        while i < node.num_children():
-            i, key, value = self.handle_dictelement(node, i)
-            keys.append(key)
-            values.append(value)
-            i += 1
-        return ast.Dict(keys, values, atom_node.get_lineno(),
-                                      atom_node.get_column())
-    
-    def handle_setdisplay(self, node, atom_node):
-        elts = []
-        i = 0
-        while i < node.num_children():
-            expr = self.handle_expr(node.get_child(i))
-            elts.append(expr)
-            i += 2
-        return ast.Set(elts, atom_node.get_lineno(),
-                             atom_node.get_column())
+        elt = self.handle_expr(listcomp_node.children[0])
+        comps = self.comprehension_helper(listcomp_node.children[1])
+        new_node = ast.ListComp (elt, comps)
+        new_node.lineno = listcomp_node.lineno
+        new_node.col_offset = listcomp_node.col_offset
+        return new_node
+
+    def handle_setcomp(self, set_maker):
+        elt = self.handle_expr(set_maker.children[0])
+        comps = self.comprehension_helper(set_maker.children[1])
+        new_node = ast.SetComp (elt, comps)
+        new_node.lineno = set_maker.lineno
+        new_node.col_offset = set_maker.col_offset
+        return new_node
+
+    def handle_dictcomp(self, dict_maker):
+        key = self.handle_expr(dict_maker.children[0])
+        value = self.handle_expr(dict_maker.children[2])
+        comps = self.comprehension_helper(dict_maker.children[3])
+        new_node = ast.DictComp (key, value, comps)
+        new_node.lineno = dict_maker.lineno
+        new_node.col_offset = dict_maker.col_offset
+        return new_node
 
     def handle_exprlist(self, exprlist, context):
         exprs = []
-        for i in range(0, exprlist.num_children(), 2):
-            child = exprlist.get_child(i)
+        for i in range(0, len(exprlist.children), 2):
+            child = exprlist.children[i]
             expr = self.handle_expr(child)
             self.set_context(expr, context)
             exprs.append(expr)
--- a/ayrton/parser/pyparser/dfa_generated.py
+++ b/ayrton/parser/pyparser/dfa_generated.py
@@ -3,7 +3,7 @@
 # TO REGENERATE THE FILE, RUN:
 #     python gendfa.py > dfa_generated.py
 
-from pypy.interpreter.pyparser import automata
+from ayrton.parser.pyparser import automata
 accepts = [True, True, True, True, True, True, True, True,
            True, True, True, False, True, True, True, True,
            True, False, False, False, True, False, False,
@@ -21,9 +21,9 @@
      '0': 5, '1': 6, '2': 6, '3': 6,
      '4': 6, '5': 6, '6': 6, '7': 6,
      '8': 6, '9': 6, ':': 15, ';': 15,
-     '<': 10, '=': 14, '>': 9, '@': 14,
+     '<': 10, '=': 14, '>': 9, '@': 15,
      'A': 1, 'B': 2, 'C': 1, 'D': 1,
-     'E': 1, 'F': 2, 'G': 1, 'H': 1,
+     'E': 1, 'F': 1, 'G': 1, 'H': 1,
      'I': 1, 'J': 1, 'K': 1, 'L': 1,
      'M': 1, 'N': 1, 'O': 1, 'P': 1,
      'Q': 1, 'R': 3, 'S': 1, 'T': 1,
@@ -31,7 +31,7 @@
      'Y': 1, 'Z': 1, '[': 15, '\\': 19,
      ']': 15, '^': 14, '_': 1, '`': 15,
      'a': 1, 'b': 2, 'c': 1, 'd': 1,
-     'e': 1, 'f': 2, 'g': 1, 'h': 1,
+     'e': 1, 'f': 1, 'g': 1, 'h': 1,
      'i': 1, 'j': 1, 'k': 1, 'l': 1,
      'm': 1, 'n': 1, 'o': 1, 'p': 1,
      'q': 1, 'r': 3, 's': 1, 't': 1,
@@ -78,14 +78,14 @@
      '2': 1, '3': 1, '4': 1, '5': 1,
      '6': 1, '7': 1, '8': 1, '9': 1,
      'A': 1, 'B': 4, 'C': 1, 'D': 1,
-     'E': 1, 'F': 4, 'G': 1, 'H': 1,
+     'E': 1, 'F': 1, 'G': 1, 'H': 1,
      'I': 1, 'J': 1, 'K': 1, 'L': 1,
      'M': 1, 'N': 1, 'O': 1, 'P': 1,
      'Q': 1, 'R': 1, 'S': 1, 'T': 1,
      'U': 1, 'V': 1, 'W': 1, 'X': 1,
      'Y': 1, 'Z': 1, '_': 1, 'a': 1,
      'b': 4, 'c': 1, 'd': 1, 'e': 1,
-     'f': 4, 'g': 1, 'h': 1, 'i': 1,
+     'f': 1, 'g': 1, 'h': 1, 'i': 1,
      'j': 1, 'k': 1, 'l': 1, 'm': 1,
      'n': 1, 'o': 1, 'p': 1, 'q': 1,
      'r': 1, 's': 1, 't': 1, 'u': 1,
--- a/ayrton/parser/pyparser/future.py
+++ b/ayrton/parser/pyparser/future.py
@@ -1,4 +1,4 @@
-from pypy.tool import stdlib___future__ as future
+import __future__ as future
 
 class FutureFlags(object):
 
@@ -52,7 +52,7 @@
             return False
 
     def skip_name(self, name):
-        from pypy.interpreter.pyparser import pygram
+        from ayrton.parser.pyparser import pygram
         if self.tok[0] == pygram.tokens.NAME and self.tok[1] == name:
             self.next()
             return True
@@ -60,7 +60,7 @@
             return False
 
     def next_feature_name(self):
-        from pypy.interpreter.pyparser import pygram
+        from ayrton.parser.pyparser import pygram
         if self.tok[0] == pygram.tokens.NAME:
             name = self.tok[1]
             self.next()
@@ -71,13 +71,13 @@
             return ''
 
     def skip_newlines(self):
-        from pypy.interpreter.pyparser import pygram
+        from ayrton.parser.pyparser import pygram
         while self.skip(pygram.tokens.NEWLINE):
             pass
 
 
 def add_future_flags(future_flags, tokens):
-    from pypy.interpreter.pyparser import pygram
+    from ayrton.parser.pyparser import pygram
     it = TokenIterator(tokens)
     result = 0
     last_position = (0, 0)
--- a/ayrton/parser/pyparser/metaparser.py
+++ b/ayrton/parser/pyparser/metaparser.py
@@ -4,11 +4,11 @@
 Inspired by Guido van Rossum's pgen2.
 """
 
-import StringIO
+import io
 import tokenize
 import token
 
-from pypy.interpreter.pyparser import parser
+from ayrton.parser.pyparser import parser
 
 
 class PgenError(Exception):
@@ -46,7 +46,7 @@
         self.arcs[label] = next
 
     def unify_state(self, old, new):
-        for label, state in self.arcs.iteritems():
+        for label, state in self.arcs.items():
             if state is old:
                 self.arcs[label] = new
 
@@ -61,7 +61,7 @@
             return False
         if len(self.arcs) != len(other.arcs):
             return False
-        for label, state in self.arcs.iteritems():
+        for label, state in self.arcs.items():
             try:
                 other_state = other.arcs[label]
             except KeyError:
@@ -89,7 +89,7 @@
             for label, sub_nfa in nfa.arcs:
                 if label is not None:
                     sub_nfa.find_unlabeled_states(arcs.setdefault(label, set()))
-        for label, nfa_set in arcs.iteritems():
+        for label, nfa_set in arcs.items():
             for st in state_stack:
                 if st.nfas == nfa_set:
                     break
@@ -104,7 +104,7 @@
     while changed:
         changed = False
         for i, state in enumerate(dfa):
-            for j in xrange(i + 1, len(dfa)):
+            for j in range(i + 1, len(dfa)):
                 other_state = dfa[j]
                 if state == other_state:
                     del dfa[j]
@@ -120,7 +120,7 @@
     def __init__(self, grammar_source):
         self.start_symbol = None
         self.dfas = {}
-        stream = StringIO.StringIO(grammar_source)
+        stream = io.StringIO(grammar_source)
         self.token_stream = tokenize.generate_tokens(stream.readline)
         self.parse()
         self.first = {}
@@ -129,7 +129,7 @@
     def build_grammar(self, grammar_cls):
         gram = grammar_cls()
         gram.start = self.start_symbol
-        names = self.dfas.keys()
+        names = list(self.dfas.keys())
         names.sort()
         names.remove(self.start_symbol)
         names.insert(0, self.start_symbol)
@@ -144,7 +144,7 @@
             states = []
             for state in dfa:
                 arcs = []
-                for label, next in state.arcs.iteritems():
+                for label, next in state.arcs.items():
                     arcs.append((self.make_label(gram, label), dfa.index(next)))
                 states.append((arcs, state.is_final))
             gram.dfas.append((states, self.make_first(gram, name)))
@@ -204,7 +204,7 @@
         return firsts
 
     def add_first_sets(self):
-        for name, dfa in self.dfas.iteritems():
+        for name, dfa in self.dfas.items():
             if name not in self.first:
                 self.get_first(name, dfa)
 
@@ -213,7 +213,7 @@
         state = dfa[0]
         all_labels = set()
         overlap_check = {}
-        for label, sub_state in state.arcs.iteritems():
+        for label, sub_state in state.arcs.items():
             if label in self.dfas:
                 if label in self.first:
                     new_labels = self.first[label]
@@ -227,7 +227,7 @@
                 all_labels.add(label)
                 overlap_check[label] = set((label,))
         inverse = {}
-        for label, their_first in overlap_check.iteritems():
+        for label, their_first in overlap_check.items():
             for sub_label in their_first:
                 if sub_label in inverse:
                     raise PgenError("ambiguous symbol with label %s"
@@ -256,10 +256,10 @@
         return False
 
     def advance_token(self):
-        data = self.token_stream.next()
+        data = next(self.token_stream)
         # Ignore comments and non-logical newlines.
         while data[0] in (tokenize.NL, tokenize.COMMENT):
-            data = self.token_stream.next()
+            data = next(self.token_stream)
         self.type, self.value = data[:2]
         self.location = data[2:]
 
--- a/ayrton/parser/pyparser/pygram.py
+++ b/ayrton/parser/pyparser/pygram.py
@@ -1,5 +1,5 @@
 import os
-from pypy.interpreter.pyparser import parser, pytoken, metaparser
+from ayrton.parser.pyparser import parser, pytoken, metaparser
 
 class PythonGrammar(parser.Grammar):
 
@@ -22,14 +22,14 @@
 
 class _Tokens(object):
     pass
-for tok_name, idx in pytoken.python_tokens.iteritems():
+for tok_name, idx in pytoken.python_tokens.items():
     setattr(_Tokens, tok_name, idx)
 tokens = _Tokens()
 
 class _Symbols(object):
     pass
 rev_lookup = {}
-for sym_name, idx in python_grammar.symbol_ids.iteritems():
+for sym_name, idx in python_grammar.symbol_ids.items():
     setattr(_Symbols, sym_name, idx)
     rev_lookup[idx] = sym_name
 syms = _Symbols()
--- a/ayrton/parser/pyparser/pyparse.py
+++ b/ayrton/parser/pyparser/pyparse.py
@@ -1,13 +1,12 @@
-from pypy.interpreter.error import OperationError
-from pypy.interpreter.pyparser import future, parser, pytokenizer, pygram, error
-from pypy.interpreter.astcompiler import consts
-from rpython.rlib import rstring
+from ayrton.parser.error import OperationError
+from ayrton.parser.pyparser import future, parser, pytokenizer, pygram, error
+from ayrton.parser.astcompiler import consts
 
 
-def recode_to_utf8(space, bytes, encoding):
+def recode_to_utf8(space, b, encoding):
     if encoding == 'utf-8':
-        return bytes
-    w_text = space.call_method(space.newbytes(bytes), "decode",
+        return b
+    w_text = space.call_method(space.newbytes(b), "decode",
                                space.newtext(encoding))
     w_recoded = space.call_method(w_text, "encode", space.newtext("utf-8"))
     return space.bytes_w(w_recoded)
@@ -33,30 +32,38 @@
             return 'iso-8859-1'
     return encoding
 
-def _check_for_encoding(s):
-    eol = s.find('\n')
+def _check_for_encoding(b):
+    """You can use a different encoding from UTF-8 by putting a specially-formatted
+    comment as the first or second line of the source code."""
+    eol = b.find(b'\n')
     if eol < 0:
-        return _check_line_for_encoding(s)[0]
-    enc, again = _check_line_for_encoding(s[:eol])
+        return _check_line_for_encoding(b)[0]
+    enc, again = _check_line_for_encoding(b[:eol])
     if enc or not again:
         return enc
-    eol2 = s.find('\n', eol + 1)
+    eol2 = b.find(b'\n', eol + 1)
     if eol2 < 0:
-        return _check_line_for_encoding(s[eol + 1:])[0]
-    return _check_line_for_encoding(s[eol + 1:eol2])[0]
+        return _check_line_for_encoding(b[eol + 1:])[0]
+    return _check_line_for_encoding(b[eol + 1:eol2])[0]
 
 
 def _check_line_for_encoding(line):
     """returns the declared encoding or None"""
     i = 0
     for i in range(len(line)):
-        if line[i] == '#':
+        if line[i] == b'#':
             break
-        if line[i] not in ' \t\014':
+        if line[i] not in b' \t\014':
             return None, False  # Not a comment, don't read the second line.
     return pytokenizer.match_encoding_declaration(line[i:]), True
 
 
+# shamelessly ripped off rpython to avoid dependency
+def check_str0(fname):
+    """A 'probe' to trigger a failure at translation time, if the
+    string was not proved to not contain NUL characters."""
+    assert '\x00' not in fname, "NUL byte in string"
+
 class CompileInfo(object):
     """Stores information about the source being compiled.
 
@@ -77,7 +84,7 @@
 
     def __init__(self, filename, mode="exec", flags=0, future_pos=(0, 0),
                  hidden_applevel=False, optimize=-1):
-        rstring.check_str0(filename)
+        check_str0(filename)
         self.filename = filename
         self.mode = mode
         self.encoding = None
@@ -108,31 +115,29 @@
         tree is handled here.
         """
         # Detect source encoding.
-        explicit_encoding = False
         enc = None
         if compile_info.flags & consts.PyCF_SOURCE_IS_UTF8:
             enc = 'utf-8'
 
         if compile_info.flags & consts.PyCF_IGNORE_COOKIE:
             textsrc = bytessrc
-        elif bytessrc.startswith("\xEF\xBB\xBF"):
+        elif bytessrc.startswith(b"\xEF\xBB\xBF"):
             bytessrc = bytessrc[3:]
             enc = 'utf-8'
             # If an encoding is explicitly given check that it is utf-8.
             decl_enc = _check_for_encoding(bytessrc)
-            explicit_encoding = (decl_enc is not None)
             if decl_enc and decl_enc != "utf-8":
                 raise error.SyntaxError("UTF-8 BOM with %s coding cookie" % decl_enc,
                                         filename=compile_info.filename)
-            textsrc = bytessrc
+            textsrc = bytessrc.decode('utf-8')
         else:
             enc = _normalize_encoding(_check_for_encoding(bytessrc))
-            explicit_encoding = (enc is not None)
             if enc is None:
                 enc = 'utf-8'
             try:
-                textsrc = recode_to_utf8(self.space, bytessrc, enc)
-            except OperationError as e:
+                # textsrc = recode_to_utf8(self.space, bytessrc, enc)
+                textsrc = bytessrc.decode(enc)
+            except UnicodeDecodeError as e:
                 # if the codec is not found, LookupError is raised.  we
                 # check using 'is_w' not to mask potential IndexError or
                 # KeyError
@@ -148,8 +153,6 @@
                 raise
 
         flags = compile_info.flags
-        if explicit_encoding:
-            flags |= consts.PyCF_FOUND_ENCODING
 
         # The tokenizer is very picky about how it wants its input.
         source_lines = textsrc.splitlines(True)
@@ -161,8 +164,6 @@
         self.prepare(_targets[compile_info.mode])
         tp = 0
         try:
-            last_value_seen = None
-            next_value_seen = None
             try:
                 # Note: we no longer pass the CO_FUTURE_* to the tokenizer,
                 # which is expected to work independently of them.  It's
@@ -177,12 +178,8 @@
                 tokens_stream = iter(tokens)
 
                 for tp, value, lineno, column, line in tokens_stream:
-                    next_value_seen = value
                     if self.add_token(tp, value, lineno, column, line):
                         break
-                    last_value_seen = value
-                last_value_seen = None
-                next_value_seen = None
 
                 if compile_info.mode == 'single':
                     for tp, value, lineno, column, line in tokens_stream:
@@ -218,14 +215,8 @@
                     msg = "expected an indented block"
                 else:
                     new_err = error.SyntaxError
-                    if (last_value_seen in ('print', 'exec') and
-                            bool(next_value_seen) and
-                            next_value_seen != '('):
-                        msg = "Missing parentheses in call to '%s'" % (
-                            last_value_seen,)
-                    else:
-                        msg = "invalid syntax"
-                raise new_err(msg, e.lineno, e.column, e.line,
+                    msg = "invalid syntax"
+                raise new_err(msg, e.lineno, e.col_offset, e.line,
                               compile_info.filename)
             else:
                 tree = self.root
--- a/ayrton/parser/pyparser/pytokenize.py
+++ b/ayrton/parser/pyparser/pytokenize.py
@@ -16,8 +16,8 @@
 """
 # ______________________________________________________________________
 
-from pypy.interpreter.pyparser import automata
-from pypy.interpreter.pyparser.dfa_generated import *
+from ayrton.parser.pyparser import automata
+from ayrton.parser.pyparser.dfa_generated import *
 
 __all__ = [ "tokenize" ]
 
--- a/ayrton/parser/pyparser/pytokenizer.py
+++ b/ayrton/parser/pyparser/pytokenizer.py
@@ -1,10 +1,10 @@
-from pypy.interpreter.pyparser import automata
-from pypy.interpreter.pyparser.pygram import tokens
-from pypy.interpreter.pyparser.pytoken import python_opmap
-from pypy.interpreter.pyparser.error import TokenError, TokenIndentationError, TabError
-from pypy.interpreter.pyparser.pytokenize import tabsize, alttabsize, whiteSpaceDFA, \
+from ayrton.parser.pyparser import automata
+from ayrton.parser.pyparser.pygram import tokens
+from ayrton.parser.pyparser.pytoken import python_opmap
+from ayrton.parser.pyparser.error import TokenError, TokenIndentationError, TabError
+from ayrton.parser.pyparser.pytokenize import tabsize, alttabsize, whiteSpaceDFA, \
     triple_quoted, endDFAs, single_quoted, pseudoDFA
-from pypy.interpreter.astcompiler import consts
+from ayrton.parser.astcompiler import consts
 
 NAMECHARS = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_'
 NUMCHARS = '0123456789'
@@ -19,6 +19,13 @@
     >>> py_encoding = re.compile(r"coding[:=]\s*([-\w.]+)")
     >>> py_encoding.search(comment)
     """
+
+    # the coding line must be ascii
+    try:
+        comment = comment.decode('ascii')
+    except UnicodeDecodeError:
+        return None
+
     index = comment.find('coding')
     if index < 0:
         return None
@@ -44,9 +51,9 @@
     return None
 
 
-def verify_utf8(token):
+def verify_identifier(token):
     for c in token:
-        if ord(c) >= 0x80:
+        if ord(c) > 0x80:
             break
     else:
         return True
@@ -54,35 +61,10 @@
         u = token.decode('utf-8')
     except UnicodeDecodeError:
         return False
-    return True
-
-def bad_utf8(location_msg, line, lnum, pos, token_list, flags):
-    msg = 'Non-UTF-8 code in %s' % location_msg
-    if not (flags & consts.PyCF_FOUND_ENCODING):
-        # this extra part of the message is added only if we found no
-        # explicit encoding
-        msg += (' but no encoding declared; see '
-                'http://python.org/dev/peps/pep-0263/ for details')
-    return TokenError(msg, line, lnum, pos, token_list)
-
-
-def verify_identifier(token):
-    # 1=ok; 0=not an identifier; -1=bad utf-8
-    for c in token:
-        if ord(c) >= 0x80:
-            break
-    else:
-        return 1
-    try:
-        u = token.decode('utf-8')
-    except UnicodeDecodeError:
-        return -1
     from pypy.objspace.std.unicodeobject import _isidentifier
     return _isidentifier(u)
 
 
-DUMMY_DFA = automata.DFA([], [])
-
 def generate_tokens(lines, flags):
     """
     This is a rewrite of pypy.module.parser.pytokenize.generate_tokens since
@@ -119,12 +101,9 @@
     altindents = [0]
     last_comment = ''
     parenlevstart = (0, 0, "")
-    async_def = False
-    async_def_nl = False
-    async_def_indent = 0
 
     # make the annotator happy
-    endDFA = DUMMY_DFA
+    endDFA = automata.DFA([], [])
     # make the annotator happy
     line = ''
     pos = 0
@@ -132,7 +111,6 @@
     strstart = (0, 0, "")
     for line in lines:
         lnum = lnum + 1
-        line = universal_newline(line)
         pos, max = 0, len(line)
 
         if contstr:
@@ -182,14 +160,8 @@
                 pos = pos + 1
             if pos == max: break
 
-            if line[pos] in '\r\n':
-                # skip blank lines
-                continue
-            if line[pos] == '#':
-                # skip full-line comment, but still check that it is valid utf-8
-                if not verify_utf8(line):
-                    raise bad_utf8("comment",
-                                   line, lnum, pos, token_list, flags)
+            if line[pos] in '#\r\n':
+                # skip comments or blank lines
                 continue
 
             if column == indents[-1]:
@@ -213,10 +185,6 @@
                     raise TokenIndentationError(err, line, lnum, 0, token_list)
                 if altcolumn != altindents[-1]:
                     raise TabError(lnum, pos, line)
-            if async_def_nl and async_def_indent >= indents[-1]:
-                async_def = False
-                async_def_nl = False
-                async_def_indent = 0
 
         else:                                  # continued statement
             if not line:
@@ -250,16 +218,11 @@
                     last_comment = ''
                 elif initial in '\r\n':
                     if parenlev <= 0:
-                        if async_def:
-                            async_def_nl = True
                         tok = (tokens.NEWLINE, last_comment, lnum, start, line)
                         token_list.append(tok)
                     last_comment = ''
                 elif initial == '#':
-                    # skip comment, but still check that it is valid utf-8
-                    if not verify_utf8(token):
-                        raise bad_utf8("comment",
-                                       line, lnum, start, token_list, flags)
+                    # skip comment
                     last_comment = token
                 elif token in triple_quoted:
                     endDFA = endDFAs[token]
@@ -291,41 +254,10 @@
                         last_comment = ''
                 elif (initial in namechars or              # ordinary name
                       ord(initial) >= 0x80):               # unicode identifier
-                    valid = verify_identifier(token)
-                    if valid <= 0:
-                        if valid == -1:
-                            raise bad_utf8("identifier", line, lnum, start + 1,
-                                           token_list, flags)
-                        # valid utf-8, but it gives a unicode char that cannot
-                        # be used in identifiers
+                    if not verify_identifier(token):
                         raise TokenError("invalid character in identifier",
                                          line, lnum, start + 1, token_list)
-
-                    if async_def:                          # inside 'async def' function
-                        if token == 'async':
-                            token_list.append((tokens.ASYNC, token, lnum, start, line))
-                        elif token == 'await':
-                            token_list.append((tokens.AWAIT, token, lnum, start, line))
-                        else:
-                            token_list.append((tokens.NAME, token, lnum, start, line))
-                    elif token == 'async':                 # async token, look ahead
-                        #ahead token
-                        if pos < max:
-                            async_end = pseudoDFA.recognize(line, pos)
-                            assert async_end >= 3
-                            async_start = async_end - 3
-                            assert async_start >= 0
-                            ahead_token = line[async_start:async_end]
-                            if ahead_token == 'def':
-                                async_def = True
-                                async_def_indent = indents[-1]
-                                token_list.append((tokens.ASYNC, token, lnum, start, line))
-                            else:
-                                token_list.append((tokens.NAME, token, lnum, start, line))
-                        else:
-                            token_list.append((tokens.NAME, token, lnum, start, line))
-                    else:
-                        token_list.append((tokens.NAME, token, lnum, start, line))
+                    token_list.append((tokens.NAME, token, lnum, start, line))
                     last_comment = ''
                 elif initial == '\\':                      # continued stmt
                     continued = 1
@@ -369,14 +301,3 @@
 
     token_list.append((tokens.ENDMARKER, '', lnum, pos, line))
     return token_list
-
-
-def universal_newline(line):
-    # show annotator that indexes below are non-negative
-    line_len_m2 = len(line) - 2
-    if line_len_m2 >= 0 and line[-2] == '\r' and line[-1] == '\n':
-        return line[:line_len_m2] + '\n'
-    line_len_m1 = len(line) - 1
-    if line_len_m1 >= 0 and line[-1] == '\r':
-        return line[:line_len_m1] + '\n'
-    return line
--- a/ayrton/parser/astcompiler/fstring.py
+++ b/ayrton/parser/astcompiler/fstring.py
@@ -1,13 +1,13 @@
-from pypy.interpreter.astcompiler import ast, consts
-from pypy.interpreter.pyparser import parsestring
-from pypy.interpreter import error
-from pypy.interpreter import unicodehelper
-from rpython.rlib.rstring import StringBuilder
+from ayrton.parser.astcompiler import consts
+from ayrton.parser.pyparser import parsestring
+from ayrton.parser import error
+# from ayrton.parser import unicodehelper
+# from rpython.rlib.rstring import StringBuilder
+import ast
 
 
 def add_constant_string(astbuilder, joined_pieces, w_string, atom_node):
-    space = astbuilder.space
-    is_unicode = space.isinstance_w(w_string, space.w_unicode)
+    is_unicode = type(w_string) == str
     # Implement implicit string concatenation.
     if joined_pieces:
         prev = joined_pieces[-1]
@@ -18,21 +18,22 @@
             w_string = space.add(prev.s, w_string)
             del joined_pieces[-1]
     node = ast.Str if is_unicode else ast.Bytes
-    joined_pieces.append(node(w_string, atom_node.get_lineno(),
-                                        atom_node.get_column()))
+
+    new_node = node(w_string)
+    new_node.lineno = atom_node.lineno
+    new_node.col_offset = atom_node.col_offset
+    joined_pieces.append(new_node)
 
 def f_constant_string(astbuilder, joined_pieces, u, atom_node):
-    space = astbuilder.space
-    add_constant_string(astbuilder, joined_pieces, space.newunicode(u),
-                        atom_node)
+    add_constant_string(astbuilder, joined_pieces, u, atom_node)
 
 def f_string_compile(astbuilder, source, atom_node):
     # Note: a f-string is kept as a single literal up to here.
     # At this point only, we recursively call the AST compiler
     # on all the '{expr}' parts.  The 'expr' part is not parsed
     # or even tokenized together with the rest of the source code!
-    from pypy.interpreter.pyparser import pyparse
-    from pypy.interpreter.astcompiler.astbuilder import ast_from_node
+    from ayrton.parser.pyparser import pyparse
+    from ayrton.parser.astcompiler.astbuilder import ast_from_node
 
     # complain if 'source' is only whitespace or an empty string
     for c in source:
@@ -215,9 +216,11 @@
 
     # And now create the FormattedValue node that represents this
     # entire expression with the conversion and format spec.
-    return ast.FormattedValue(expr.body, conversion, format_spec,
-                              atom_node.get_lineno(),
-                              atom_node.get_column())
+    new_node = ast.FormattedValue(expr.body, conversion, format_spec)
+    new_node.lineno = atom_node.lineno
+    new_node.col_offset = atom_node.col_offset
+
+    return new_node
 
 
 def fstring_find_literal(astbuilder, fstr, atom_node, rec):
@@ -329,26 +332,25 @@
     # In this way it cannot be grabbed later for being used as a
     # docstring.  In codegen.py we still special-case length-1 lists
     # and avoid calling "BUILD_STRING 1" in this case.
-    space = astbuilder.space
     values = [node for node in joined_pieces
                    if not isinstance(node, ast.Str)
-                      or space.is_true(node.s)]
-    return ast.JoinedStr(values, atom_node.get_lineno(),
-                                 atom_node.get_column())
+                      or node.s != '']
+    new_node = ast.JoinedStr(values)
+    new_node.lineno = atom_node.lineno
+    new_node.col_offset = atom_node.col_offset
+    return new_node
 
 
 def string_parse_literal(astbuilder, atom_node):
-    space = astbuilder.space
     encoding = astbuilder.compile_info.encoding
     joined_pieces = []
     fmode = False
     try:
-        for i in range(atom_node.num_children()):
-            w_next = parsestring.parsestr(
-                    space, encoding, atom_node.get_child(i).get_value())
+        for i in range(len(atom_node.children)):
+            w_next = parsestring.parsestr(encoding,
+                                          atom_node.children[i].value)
             if not isinstance(w_next, parsestring.W_FString):
-                add_constant_string(astbuilder, joined_pieces, w_next,
-                                    atom_node)
+                add_constant_string(astbuilder, joined_pieces, w_next,atom_node)
             else:
                 parse_f_string(astbuilder, joined_pieces, w_next, atom_node)
                 fmode = True
--- a/ayrton/parser/astcompiler/misc.py
+++ b/ayrton/parser/astcompiler/misc.py
@@ -1,33 +1,5 @@
-from pypy.interpreter import gateway
-from rpython.rlib.objectmodel import we_are_translated
-from rpython.rlib.unroll import unrolling_iterable
-
-
-app = gateway.applevel("""
-def syntax_warning(msg, fn, lineno, offset):
-    import warnings
-    try:
-        warnings.warn_explicit(msg, SyntaxWarning, fn, lineno)
-    except SyntaxWarning:
-        raise SyntaxError(msg, (fn, lineno, offset, msg))
-""", filename=__file__)
-_emit_syntax_warning = app.interphook("syntax_warning")
-del app
-
-def syntax_warning(space, msg, fn, lineno, offset):
-    """Raise an applevel SyntaxWarning.
-
-    If the user has set this warning to raise an error, a SyntaxError will be
-    raised."""
-    w_msg = space.newtext(msg)
-    w_filename = space.newfilename(fn)
-    w_lineno = space.newint(lineno)
-    w_offset = space.newint(offset)
-    _emit_syntax_warning(space, w_msg, w_filename, w_lineno, w_offset)
-
-
 def parse_future(tree, feature_flags):
-    from pypy.interpreter.astcompiler import ast
+    from ayrton.parser.astcompiler import ast
     future_lineno = 0
     future_column = 0
     flags = 0
@@ -75,19 +47,41 @@
     # XXX Warn about using True and False
 
 
+# shamelessly lifted off rpython
+class unrolling_iterable:
+
+    def __init__(self, iterable):
+        self._items = list(iterable)
+        self._head = _unroller(self._items)
+
+    def __iter__(self):
+        return iter(self._items)
+
+    def get_unroller(self):
+        return self._head
+
+
+# ditto
+class _unroller:
+
+    def __init__(self, items, i=0):
+        self._items = items
+        self._i = i
+        self._next = None
+
+    def step(self):
+        v = self._items[self._i]
+        if self._next is None:
+            self._next = _unroller(self._items, self._i+1)
+        return v, self._next
+
+
 def dict_to_switch(d):
     """Convert of dictionary with integer keys to a switch statement."""
     def lookup(query):
-        if we_are_translated():
-            for key, value in unrolling_iteritems:
-                if key == query:
-                    return value
-            else:
-                raise KeyError
-        else:
-            return d[query]
+        return d[query]
     lookup._always_inline_ = True
-    unrolling_iteritems = unrolling_iterable(d.iteritems())
+    unrolling_items = unrolling_iterable(d.items())
     return lookup
 
 
--- a/ayrton/parser/astcompiler/tools/asdl_py.py
+++ b/ayrton/parser/astcompiler/tools/asdl_py.py
@@ -56,7 +56,6 @@
 
     def visitSum(self, sum, base):
         if is_simple_sum(sum):
-            assert not sum.attributes
             self.emit("class %s(AST):" % (base,))
             self.emit("@staticmethod", 1)
             self.emit("def from_object(space, w_node):", 1)
@@ -86,7 +85,7 @@
             self.emit("class %s(AST):" % (base,))
             if sum.attributes:
                 self.emit("")
-                args = ", ".join(attr.name for attr in sum.attributes)
+                args = ", ".join(attr.name.value for attr in sum.attributes)
                 self.emit("def __init__(self, %s):" % (args,), 1)
                 for attr in sum.attributes:
                     self.visit(attr)
@@ -102,8 +101,8 @@
                           % (typ.name,), 3)
             self.emit("raise oefmt(space.w_TypeError,", 2)
             self.emit("        \"Expected %s node, got %%T\", w_node)" % (base,), 2)
-            self.emit("State.ast_type(%r, 'AST', None, %s)" %
-                      (base, [attr.name for attr in sum.attributes]))
+            self.emit("State.ast_type('%r', 'AST', None, %s)" %
+                      (base, [repr(attr.name) for attr in sum.attributes]))
             self.emit("")
             for cons in sum.types:
                 self.visit(cons, base, sum.attributes)
@@ -209,7 +208,7 @@
         else:
             value = self.get_value_extractor(field, "w_%s" % (field.name,))
             lines = ["_%s = %s" % (field.name, value)]
-            if not field.opt and field.type not in ("int",):
+            if not field.opt and field.type.value not in ("int",):
                 lines.append("if _%s is None:" % (field.name,))
                 lines.append("    raise_required_value(space, w_node, '%s')"
                              % (field.name,))
@@ -255,27 +254,20 @@
     def make_mutate_over(self, cons, name):
         self.emit("def mutate_over(self, visitor):", 1)
         for field in cons.fields:
-            if (field.type not in asdl.builtin_types and
-                field.type not in self.data.simple_types):
+            if (field.type.value not in asdl.builtin_types and
+                field.type.value not in self.data.simple_types):
                 if field.opt or field.seq:
                     level = 3
                     self.emit("if self.%s:" % (field.name,), 2)
                 else:
                     level = 2
                 if field.seq:
-                    sub = field.name
-                    self.emit("for i in range(len(self.{})):".format(sub),
-                        level)
-                    self.emit("if self.{}[i] is not None:".format(sub),
-                        level + 1)
-                    self.emit(
-                        "self.{0}[i] = self.{0}[i].mutate_over(visitor)".format(sub),
-                        level + 2)
+                    sub = (field.name,)
+                    self.emit("visitor._mutate_sequence(self.%s)" % sub, level)
                 else:
-                    sub = field.name
-                    self.emit(
-                        "self.{0} = self.{0}.mutate_over(visitor)".format(sub),
-                        level)
+                    sub = (field.name, field.name)
+                    self.emit("self.%s = self.%s.mutate_over(visitor)" % sub,
+                              level)
         self.emit("return visitor.visit_%s(self)" % (name,), 2)
         self.emit("")
 
@@ -289,8 +281,8 @@
         self.emit("")
         self.make_mutate_over(cons, cons.name)
         self.make_converters(cons.fields, cons.name, extra_attributes)
-        self.emit("State.ast_type(%r, '%s', %s)" %
-                  (cons.name, base, [f.name for f in cons.fields]))
+        self.emit("State.ast_type('%r', '%s', %s)" %
+                  (cons.name, base, [repr(f.name) for f in cons.fields]))
         self.emit("")
 
     def visitField(self, field):
@@ -306,8 +298,7 @@
         self.emit("def visit_sequence(self, seq):", 1)
         self.emit("if seq is not None:", 2)
         self.emit("for node in seq:", 3)
-        self.emit("if node is not None:", 4)
-        self.emit("node.walkabout(self)", 5)
+        self.emit("node.walkabout(self)", 4)
         self.emit("")
         self.emit("def visit_kwonlydefaults(self, seq):", 1)
         self.emit("if seq is not None:", 2)
@@ -318,6 +309,11 @@
         self.emit("def default_visitor(self, node):", 1)
         self.emit("raise NodeVisitorNotImplemented", 2)
         self.emit("")
+        self.emit("def _mutate_sequence(self, seq):", 1)
+        self.emit("for i in range(len(seq)):", 2)
+        self.emit("if seq[i] is not None:", 3)
+        self.emit("seq[i] = seq[i].mutate_over(self)", 4)
+        self.emit("")
         super(ASTVisitorVisitor, self).visitModule(mod)
         self.emit("")
 
@@ -365,8 +361,8 @@
         self.emit("")
 
     def visitField(self, field):
-        if (field.type not in asdl.builtin_types and
-            field.type not in self.data.simple_types):
+        if (field.type.value not in asdl.builtin_types and
+            field.type.value not in self.data.simple_types):
             level = 2
             template = "node.%s.walkabout(self)"
             if field.seq:
@@ -407,7 +403,7 @@
             if isinstance(tp.value, asdl.Sum):
                 sum = tp.value
                 if is_simple_sum(sum):
-                    simple_types.add(tp.name)
+                    simple_types.add(tp.name.value)
                 else:
                     attrs = [field for field in sum.attributes]
                     for cons in sum.types:
@@ -415,7 +411,7 @@
                         cons_attributes[cons] = attrs
             else:
                 prod = tp.value
-                prod_simple.add(tp.name)
+                prod_simple.add(tp.name.value)
                 add_masks(prod.fields, prod)
         prod_simple.update(simple_types)
         self.cons_attributes = cons_attributes
@@ -443,8 +439,8 @@
 def check_string(space, w_obj):
     if not (space.isinstance_w(w_obj, space.w_bytes) or
             space.isinstance_w(w_obj, space.w_unicode)):
-        raise oefmt(space.w_TypeError,
-                    "AST string must be of type str or unicode")
+        raise OperationError(space.w_TypeError, space.wrap(
+                'AST string must be of type str or unicode'))
     return w_obj
 
 def get_field(space, w_node, name, optional):
@@ -459,7 +455,6 @@
 
 class AST(object):
     __metaclass__ = extendabletype
-    _attrs_ = ['lineno', 'col_offset']
 
     def walkabout(self, visitor):
         raise AssertionError("walkabout() implementation not provided")
--- a/ayrton/parser/error.py
+++ b/ayrton/parser/error.py
@@ -1,14 +1,10 @@
-import cStringIO
+import io
 import itertools
 import os
 import sys
 import traceback
 from errno import EINTR
 
-from rpython.rlib import jit
-from rpython.rlib.objectmodel import we_are_translated, specialize
-from rpython.rlib import rstack, rstackovf
-
 from ayrton.parser import debug
 
 
@@ -32,11 +28,12 @@
 
     _w_value = None
     _application_traceback = None
-    _context_recorded = False
+    w_cause = None
 
-    def __init__(self, w_type, w_value, tb=None):
+    def __init__(self, w_type, w_value, tb=None, w_cause=None):
         self.setup(w_type, w_value)
         self._application_traceback = tb
+        self.w_cause = w_cause
 
     def setup(self, w_type, w_value=None):
         assert w_type is not None
@@ -60,19 +57,14 @@
         "Check if this is an exception that should better not be caught."
         return (self.match(space, space.w_SystemExit) or
                 self.match(space, space.w_KeyboardInterrupt))
-        # note: an extra case is added in OpErrFmtNoArgs
 
     def __str__(self):
         "NOT_RPYTHON: Convenience for tracebacks."
         s = self._w_value
-        space = getattr(self.w_type, 'space', None)
-        if space is not None:
-            if self.__class__ is not OperationError and s is None:
+        if self.__class__ is not OperationError and s is None:
+            space = getattr(self.w_type, 'space')
+            if space is not None:
                 s = self._compute_value(space)
-            try:
-                s = space.str_w(s)
-            except Exception:
-                pass
         return '[%s: %s]' % (self.w_type, s)
 
     def __repr__(self):
@@ -81,8 +73,6 @@
 
     def errorstr(self, space, use_repr=False):
         "The exception class and value, as a string."
-        if not use_repr:    # see write_unraisable()
-            self.normalize_exception(space)
         w_value = self.get_w_value(space)
         if space is None:
             # this part NOT_RPYTHON
@@ -90,8 +80,11 @@
             exc_value = str(w_value)
         else:
             w = space.wrap
-            exc_typename = space.str_w(
-                space.getattr(self.w_type, w('__name__')))
+            if space.is_w(space.type(self.w_type), space.w_text):
+                exc_typename = space.str_w(self.w_type)
+            else:
+                exc_typename = space.str_w(
+                    space.getattr(self.w_type, w('__name__')))
             if space.is_w(w_value, space.w_None):
                 exc_value = ""
             else:
@@ -102,8 +95,7 @@
                         exc_value = space.str_w(space.str(w_value))
                 except OperationError:
                     # oups, cannot __str__ the exception object
-                    exc_value = ("<exception %s() failed>" %
-                                 ("repr" if use_repr else "str"))
+                    exc_value = "<oups, exception object itself cannot be str'd>"
         if not exc_value:
             return exc_typename
         else:
@@ -157,7 +149,7 @@
         application-level traceback, useful to debug the interpreter."""
         if file is None:
             file = sys.stderr
-        f = cStringIO.StringIO()
+        f = io.StringIO()
         for i in range(len(self.debug_excs)-1, -1, -1):
             print >> f, "Traceback (interpreter-level):"
             traceback.print_tb(self.debug_excs[i][2], file=f)
@@ -171,7 +163,6 @@
         if AUTO_DEBUG:
             debug.fire(self)
 
-    @jit.unroll_safe
     def normalize_exception(self, space):
         """Normalize the OperationError.  In other words, fix w_type and/or
         w_value to make sure that the __class__ of w_value is exactly w_type.
@@ -216,6 +207,13 @@
                         # raise Type, X: assume X is the constructor argument
                         w_value = space.call_function(w_type, w_value)
                     w_type = self._exception_getclass(space, w_value)
+            if self.w_cause:
+                # ensure w_cause is of a valid type
+                if space.is_none(self.w_cause):
+                    pass
+                else:
+                    self._exception_getclass(space, self.w_cause, "exception causes")
+                space.setattr(w_value, space.wrap("__cause__"), self.w_cause)
             if self._application_traceback:
                 from pypy.interpreter.pytraceback import PyTraceback
                 from pypy.module.exceptions.interp_exceptions import W_BaseException
@@ -233,8 +231,9 @@
             w_inst = w_type
             w_instclass = self._exception_getclass(space, w_inst)
             if not space.is_w(w_value, space.w_None):
-                raise oefmt(space.w_TypeError,
-                            "instance exception may not have a separate value")
+                raise OperationError(space.w_TypeError,
+                                     space.wrap("instance exception may not "
+                                                "have a separate value"))
             w_value = w_inst
             w_type = w_instclass
 
@@ -251,50 +250,40 @@
 
     def write_unraisable(self, space, where, w_object=None,
                          with_traceback=False, extra_line=''):
-        # Note: since Python 3.5, unraisable exceptions are always
-        # printed with a traceback.  Setting 'with_traceback=False'
-        # only asks for a different format, starting with the message
-        # "Exception Xxx ignored".
         if w_object is None:
             objrepr = ''
         else:
             try:
                 objrepr = space.str_w(space.repr(w_object))
             except OperationError:
-                objrepr = "<object repr() failed>"
+                objrepr = '?'
         #
         try:
-            try:
-                self.normalize_exception(space)
-            except OperationError:
-                pass
-            w_t = self.w_type
-            w_v = self.get_w_value(space)
-            w_tb = space.wrap(self.get_traceback())
-            if where or objrepr:
-                if with_traceback:
-                    first_line = 'From %s%s:\n' % (where, objrepr)
-                else:
-                    first_line = 'Exception ignored in: %s%s\n' % (
-                        where, objrepr)
+            if with_traceback:
+                try:
+                    self.normalize_exception(space)
+                except OperationError:
+                    pass
+                w_t = self.w_type
+                w_v = self.get_w_value(space)
+                w_tb = space.wrap(self.get_traceback())
+                space.appexec([space.wrap(where),
+                               space.wrap(objrepr),
+                               space.wrap(extra_line),
+                               w_t, w_v, w_tb],
+                """(where, objrepr, extra_line, t, v, tb):
+                    import sys, traceback
+                    if where or objrepr:
+                        sys.stderr.write('From %s%s:\\n' % (where, objrepr))
+                    if extra_line:
+                        sys.stderr.write(extra_line)
+                    traceback.print_exception(t, v, tb)
+                """)
             else:
-                # Note that like CPython, we don't normalize the
-                # exception here.  So from `'foo'.index('bar')` you get
-                # "Exception ValueError: 'substring not found' in x ignored"
-                # but from `raise ValueError('foo')` you get
-                # "Exception ValueError: ValueError('foo',) in x ignored"
-                first_line = ''
-            space.appexec([space.wrap(first_line),
-                           space.wrap(extra_line),
-                           w_t, w_v, w_tb],
-            """(first_line, extra_line, t, v, tb):
-                import sys
-                sys.stderr.write(first_line)
-                if extra_line:
-                    sys.stderr.write(extra_line)
-                import traceback
-                traceback.print_exception(t, v, tb)
-            """)
+                msg = 'Exception %s in %s%s ignored\n' % (
+                    self.errorstr(space, use_repr=True), where, objrepr)
+                space.call_method(space.sys.get('stderr'), 'write',
+                                  space.wrap(msg))
         except OperationError:
             pass   # ignored
 
@@ -322,216 +311,45 @@
             tb.frame.mark_as_escaped()
         return tb
 
-    def has_any_traceback(self):
-        return self._application_traceback is not None
-
-    def set_cause(self, space, w_cause):
-        if w_cause is None:
-            return
-        # ensure w_cause is of a valid type
-        if space.is_none(w_cause):
-            pass
-        else:
-            self._exception_getclass(space, w_cause, "exception causes")
-        w_value = self.get_w_value(space)
-        space.setattr(w_value, space.wrap("__cause__"), w_cause)
-
     def set_traceback(self, traceback):
-        """Set the current traceback."""
+        """Set the current traceback.  It should either be a traceback
+        pointing to some already-escaped frame, or a traceback for the
+        current frame.  To support the latter case we do not mark the
+        frame as escaped.  The idea is that it will be marked as escaping
+        only if the exception really propagates out of this frame, by
+        executioncontext.leave() being called with got_exception=True.
+        """
         self._application_traceback = traceback
 
-    def remove_traceback_module_frames(self, *module_names):
+    def remove_traceback_module_frames(self, module_name):
         from pypy.interpreter.pytraceback import PyTraceback
         tb = self._application_traceback
         while tb is not None and isinstance(tb, PyTraceback):
-            if tb.frame.pycode.co_filename not in module_names:
+            if tb.frame.pycode.co_filename != module_name:
                 break
             tb = tb.next
         self._application_traceback = tb
 
-    def record_context(self, space, ec):
-        """Record a __context__ for this exception if one exists.
+    def record_context(self, space, frame):
+        """Record a __context__ for this exception from the current
+        frame if one exists.
+
+        __context__ is otherwise lazily determined from the
+        traceback. However the current frame.last_exception must be
+        checked for a __context__ before this OperationError overwrites
+        it (making the previous last_exception unavailable later on).
         """
-        if self._context_recorded:
-            return
-        last = ec.sys_exc_info()
-        try:
-            if last is not None:
-                self.chain_exceptions(space, last)
-        finally:
-            self._context_recorded = True
-
-    def chain_exceptions(self, space, context):
-        """Attach another OperationError as __context__."""
-        self.normalize_exception(space)
-        w_value = self.get_w_value(space)
-        context.normalize_exception(space)
-        w_context = context.get_w_value(space)
-        if not space.is_w(w_value, w_context):
-            _break_context_cycle(space, w_value, w_context)
+        last_exception = frame.last_exception
+        if (last_exception is not None and not frame.hide() or
+            last_exception is get_cleared_operation_error(space)):
+            # normalize w_value so setup_context can check for cycles
+            self.normalize_exception(space)
+            w_value = self.get_w_value(space)
+            w_last = last_exception.get_w_value(space)
+            w_context = setup_context(space, w_value, w_last, lazy=True)
             space.setattr(w_value, space.wrap('__context__'), w_context)
 
-    # A simplified version of _PyErr_TrySetFromCause, which returns a
-    # new exception of the same class, but with another error message.
-    # This only works for exceptions which have just a single message,
-    # and no other attribute.
-    # Otherwise the same OperationError is returned.
-    def try_set_from_cause(self, space, message):
-        from pypy.module.exceptions.interp_exceptions import W_BaseException
-        self.normalize_exception(space)
-        w_value = self.get_w_value(space)
-        if not isinstance(w_value, W_BaseException):
-            return self
-        exc = w_value
-        # "args" should be empty or contain a single string
-        if len(exc.args_w) == 0:
-            pass
-        elif len(exc.args_w) == 1:
-            if not space.isinstance_w(exc.args_w[0], space.w_unicode):
-                return self
-        else:
-            return self
-        # No instance attribute.
-        if exc.w_dict and space.is_true(exc.w_dict):
-            return self
-        # Try to create the new exception.
-        try:
-            new_error = oefmt(space.type(w_value),
-                              "%s (%T: %S)", message, w_value, w_value)
-            new_error.normalize_exception(space)
-            new_error.set_cause(space, w_value)
-            # Copy the traceback, but it does not escape.
-            new_error.set_traceback(self._application_traceback)
-        except OperationError:
-            # Return the original error
-            return self
-        return new_error
-
 
-def _break_context_cycle(space, w_value, w_context):
-    """Break reference cycles in the __context__ chain.
-
-    This is O(chain length) but context chains are usually very short
-    """
-    while True:
-        w_next = space.getattr(w_context, space.wrap('__context__'))
-        if space.is_w(w_next, space.w_None):
-            break
-        if space.is_w(w_next, w_value):
-            space.setattr(w_context, space.wrap('__context__'), space.w_None)
-            break
-        w_context = w_next
-
-
-class ClearedOpErr:
-    def __init__(self, space):
-        self.operr = OperationError(space.w_None, space.w_None)
-
-def get_cleared_operation_error(space):
-    return space.fromcache(ClearedOpErr).operr
-
-# ____________________________________________________________
-# optimization only: avoid the slowest operation -- the string
-# formatting with '%' -- in the common case were we don't
-# actually need the message.  Only supports %s and %d.
-
-_fmtcache = {}
-_fmtcache2 = {}
-_FMTS = tuple('8NRSTds')
-
-def decompose_valuefmt(valuefmt):
-    """Returns a tuple of string parts extracted from valuefmt,
-    and a tuple of format characters."""
-    formats = []
-    parts = valuefmt.split('%')
-    i = 1
-    while i < len(parts):
-        if parts[i].startswith(_FMTS):
-            formats.append(parts[i][0])
-            parts[i] = parts[i][1:]
-            i += 1
-        elif parts[i] == '':    # support for '%%'
-            parts[i-1] += '%' + parts[i+1]
-            del parts[i:i+2]
-        else:
-            fmts = '%%%s or %%%s' % (', %'.join(_FMTS[:-1]), _FMTS[-1])
-            raise ValueError("invalid format string (only %s supported)" %
-                             fmts)
-    assert len(formats) > 0, "unsupported: no % command found"
-    return tuple(parts), tuple(formats)
-
-def get_operrcls2(valuefmt):
-    valuefmt = valuefmt.decode('ascii')
-    strings, formats = decompose_valuefmt(valuefmt)
-    assert len(strings) == len(formats) + 1
-    try:
-        OpErrFmt = _fmtcache2[formats]
-    except KeyError:
-        from rpython.rlib.unroll import unrolling_iterable
-        attrs = ['x%d' % i for i in range(len(formats))]
-        entries = unrolling_iterable(zip(itertools.count(), formats, attrs))
-
-        class OpErrFmt(OperationError):
-            def __init__(self, w_type, strings, *args):
-                assert len(args) == len(strings) - 1
-                self.xstrings = strings
-                for i, _, attr in entries:
-                    setattr(self, attr, args[i])
-                self.setup(w_type)
-
-            def _compute_value(self, space):
-                lst = [None] * (len(formats) + len(formats) + 1)
-                for i, fmt, attr in entries:
-                    lst[i + i] = self.xstrings[i]
-                    value = getattr(self, attr)
-                    if fmt == 'd':
-                        result = str(value).decode('ascii')
-                    elif fmt == 'R':
-                        result = space.unicode_w(space.repr(value))
-                    elif fmt == 'S':
-                        result = space.unicode_w(space.str(value))
-                    elif fmt == 'T':
-                        result = space.type(value).name.decode('utf-8')
-                    elif fmt == 'N':
-                        result = value.getname(space)
-                    elif fmt == '8':
-                        result = value.decode('utf-8')
-                    else:
-                        result = unicode(value)
-                    lst[i + i + 1] = result
-                lst[-1] = self.xstrings[-1]
-                return u''.join(lst)
-        #
-        _fmtcache2[formats] = OpErrFmt
-    return OpErrFmt, strings
-
-class OpErrFmtNoArgs(OperationError):
-    def __init__(self, w_type, value):
-        self._value = value
-        self.setup(w_type)
-
-    def _compute_value(self, space):
-        return self._value.decode('utf-8')
-
-    def async(self, space):
-        # also matches a RuntimeError("maximum rec.") if the stack is
-        # still almost full, because in this case it might be a better
-        # idea to propagate the exception than eat it
-        if (self.w_type is space.w_RecursionError and
-            self._value == "maximum recursion depth exceeded" and
-            rstack.stack_almost_full()):
-            return True
-        return OperationError.async(self, space)
-
-@specialize.memo()
-def get_operr_class(valuefmt):
-    try:
-        result = _fmtcache[valuefmt]
-    except KeyError:
-        result = _fmtcache[valuefmt] = get_operrcls2(valuefmt)
-    return result
-
-@specialize.arg(1)
 def oefmt(w_type, valuefmt, *args):
     """Equivalent to OperationError(w_type, space.wrap(valuefmt % args)).
     More efficient in the (common) case where the value is not actually
@@ -543,7 +361,6 @@
     %8 - The result of arg.decode('utf-8')
     %N - The result of w_arg.getname(space)
     %R - The result of space.unicode_w(space.repr(w_arg))
-    %S - The result of space.unicode_w(space.str(w_arg))
     %T - The result of space.type(w_arg).name
 
     """
@@ -551,204 +368,3 @@
         return OpErrFmtNoArgs(w_type, valuefmt)
     OpErrFmt, strings = get_operr_class(valuefmt)
     return OpErrFmt(w_type, strings, *args)
-
-# ____________________________________________________________
-
-# Utilities
-from rpython.tool.ansi_print import ansi_print
-
-def debug_print(text, file=None, newline=True):
-    # 31: ANSI color code "red"
-    ansi_print(text, esc="31", file=file, newline=newline)
-
-try:
-    WindowsError
-except NameError:
-    _WINDOWS = False
-else:
-    _WINDOWS = True
-
-    def wrap_windowserror(space, e, w_filename=None):
-        XXX    # WindowsError no longer exists in Py3.5
-        from rpython.rlib import rwin32
-
-        winerror = e.winerror
-        try:
-            msg = rwin32.FormatError(winerror)
-        except ValueError:
-            msg = 'Windows Error %d' % winerror
-        exc = space.w_WindowsError
-        if w_filename is not None:
-            w_error = space.call_function(exc, space.wrap(winerror),
-                                          space.wrap(msg), w_filename)
-        else:
-            w_error = space.call_function(exc, space.wrap(winerror),
-                                          space.wrap(msg))
-        return OperationError(exc, w_error)
-
-@specialize.arg(3, 6)
-def wrap_oserror2(space, e, w_filename=None, exception_name='w_OSError',
-                  w_exception_class=None, w_filename2=None, eintr_retry=False):
-    """A double API here:
-
-        * if eintr_retry is False, always return the OperationError to
-          be raised by the caller.  It can possibly be about EINTR
-          (checksignals() is still called here).
-
-        * if eintr_retry is True (PEP 475 compliant API for retrying
-          system calls failing with EINTR), then this function raises
-          the OperationError directly, or for EINTR it calls
-          checksignals() and returns None in case the original
-          operation should be retried.
-    """
-    assert isinstance(e, OSError)
-
-    if _WINDOWS and isinstance(e, WindowsError):
-        return wrap_windowserror(space, e, w_filename)
-
-    if w_exception_class is None:
-        w_exc = getattr(space, exception_name)
-    else:
-        w_exc = w_exception_class
-    operror = _wrap_oserror2_impl(space, e, w_filename, w_filename2, w_exc,
-                                  eintr_retry)
-    if eintr_retry:
-        assert operror is None   # otherwise, _wrap_oserror2_impl() has raised
-    else:
-        assert operror is not None   # tell the annotator we don't return None
-        return operror
-
-def _wrap_oserror2_impl(space, e, w_filename, w_filename2, w_exc, eintr_retry):
-    # move the common logic in its own function, instead of having it
-    # duplicated 4 times in all 4 specialized versions of wrap_oserror2()
-    errno = e.errno
-
-    if errno == EINTR:
-        space.getexecutioncontext().checksignals()
-        if eintr_retry:
-            return None
-
-    try:
-        msg = strerror(errno)
-    except ValueError:
-        msg = u'error %d' % errno
-    if w_filename is not None:
-        if w_filename2 is not None:
-            w_error = space.call_function(w_exc, space.wrap(errno),
-                                          space.wrap(msg), w_filename,
-                                          space.w_None, w_filename2)
-        else:
-            w_error = space.call_function(w_exc, space.wrap(errno),
-                                          space.wrap(msg), w_filename)
-    else:
-        w_error = space.call_function(w_exc, space.wrap(errno),
-                                      space.wrap(msg))
-    operror = OperationError(w_exc, w_error)
-    if eintr_retry:
-        raise operror
-    return operror
-_wrap_oserror2_impl._dont_inline_ = True
-
-@specialize.arg(3, 6)
-def wrap_oserror(space, e, filename=None, exception_name='w_OSError',
-                 w_exception_class=None, filename2=None, eintr_retry=False):
-    w_filename = None
-    w_filename2 = None
-    if filename is not None:
-        w_filename = space.wrap(filename)
-        if filename2 is not None:
-            w_filename2 = space.wrap(filename2)
-    return wrap_oserror2(space, e, w_filename,
-                         exception_name=exception_name,
-                         w_exception_class=w_exception_class,
-                         w_filename2=w_filename2,
-                         eintr_retry=eintr_retry)
-wrap_oserror._dont_inline_ = True
-
-def exception_from_saved_errno(space, w_type):
-    from rpython.rlib.rposix import get_saved_errno
-
-    errno = get_saved_errno()
-    msg = strerror(errno)
-    w_error = space.call_function(w_type, space.wrap(errno), space.wrap(msg))
-    return OperationError(w_type, w_error)
-
-def new_exception_class(space, name, w_bases=None, w_dict=None):
-    """Create a new exception type.
-    @param name: the name of the type.
-    @param w_bases: Either an exception type, or a wrapped tuple of
-                    exception types.  default is space.w_Exception.
-    @param w_dict: an optional dictionary to populate the class __dict__.
-    """
-    if '.' in name:
-        module, name = name.rsplit('.', 1)
-    else:
-        module = None
-    if w_bases is None:
-        w_bases = space.newtuple([space.w_Exception])
-    elif not space.isinstance_w(w_bases, space.w_tuple):
-        w_bases = space.newtuple([w_bases])
-    if w_dict is None:
-        w_dict = space.newdict()
-    w_exc = space.call_function(
-        space.w_type, space.wrap(name), w_bases, w_dict)
-    if module:
-        space.setattr(w_exc, space.wrap("__module__"), space.wrap(module))
-    return w_exc
-
-def new_import_error(space, w_msg, w_name, w_path):
-    """Create a new instance of ImportError.
-
-    The result corresponds to ImportError(msg, name=name, path=path)
-    """
-    return space.appexec(
-        [w_msg, w_name, w_path], """(msg, name, path):
-            return ImportError(msg, name=name, path=path)""")
-
-def raise_import_error(space, w_msg, w_name, w_path):
-    w_exc = new_import_error(space, w_msg, w_name, w_path)
-    raise OperationError(space.w_ImportError, w_exc)
-
-@jit.dont_look_inside
-def get_converted_unexpected_exception(space, e):
-    """This is used in two places when we get an non-OperationError
-    RPython exception: from gateway.py when calling an interp-level
-    function raises; and from pyopcode.py when we're exiting the
-    interpretation of the frame with an exception.  Note that it
-    *cannot* be used in pyopcode.py: that place gets a
-    ContinueRunningNormally exception from the JIT, which must not end
-    up here!
-    """
-    try:
-        if not we_are_translated():
-            raise
-        raise e
-    except KeyboardInterrupt:
-        return OperationError(space.w_KeyboardInterrupt, space.w_None)
-    except MemoryError:
-        return OperationError(space.w_MemoryError, space.w_None)
-    except rstackovf.StackOverflow as e:
-        # xxx twisted logic which happens to give the result that we
-        # want: when untranslated, a RuntimeError or its subclass
-        # NotImplementedError is caught here.  Then
-        # check_stack_overflow() will re-raise it directly.  We see
-        # the result as this exception propagates directly.  But when
-        # translated, an RPython-level RuntimeError is turned into
-        # an app-level RuntimeError by the next case.
-        rstackovf.check_stack_overflow()
-        return oefmt(space.w_RecursionError,
-                     "maximum recursion depth exceeded")
-    except RuntimeError:   # not on top of py.py
-        return OperationError(space.w_RuntimeError, space.w_None)
-    except:
-        if we_are_translated():
-            from rpython.rlib.debug import debug_print_traceback
-            debug_print_traceback()
-            extra = '; internal traceback was dumped to stderr'
-        else:
-            # when untranslated, we don't wrap into an app-level
-            # SystemError (this makes debugging tests harder)
-            raise
-        return OperationError(space.w_SystemError, space.wrap(
-            "unexpected internal exception (please report a bug): %r%s" %
-            (e, extra)))
--- a/ayrton/parser/pyparser/automata.py
+++ b/ayrton/parser/pyparser/automata.py
@@ -13,60 +13,24 @@
 # PYPY Modification: removed the EMPTY class as it's not needed here
 
 
-# PYPY Modification: DEFAULT is a singleton, used only in the pre-RPython
-# dicts (see pytokenize.py).  Then DFA.__init__() turns these dicts into
-# more compact strings.
-DEFAULT = object()
-
+# PYPY Modification: we don't need a particuliar DEFAULT class here
+#                    a simple None works fine.
+#                    (Having a DefaultClass inheriting from str makes
+#                     the annotator crash)
+DEFAULT = "\00default" # XXX hack, the rtyper does not support dict of with str|None keys
+                       # anyway using dicts doesn't seem the best final way to store these char indexed tables
 # PYPY Modification : removed all automata functions (any, maybe,
 #                     newArcPair, etc.)
 
-ERROR_STATE = chr(255)
-
 class DFA:
     # ____________________________________________________________
     def __init__(self, states, accepts, start = 0):
-        """ NOT_RPYTHON """
-        assert len(states) < 255 # no support for huge amounts of states
-        # construct string for looking up state transitions
-        string_states = [] * len(states)
-        # compute maximum
-        maximum = 0
-        for state in states:
-            for key in state:
-                if key == DEFAULT:
-                    continue
-                maximum = max(ord(key), maximum)
-        self.max_char = maximum + 1
-
-        defaults = []
-        for i, state in enumerate(states):
-            default = ERROR_STATE
-            if DEFAULT in state:
-                default = chr(state[DEFAULT])
-            defaults.append(default)
-            string_state = [default] * self.max_char
-            for key, value in state.iteritems():
-                if key == DEFAULT:
-                    continue
-                assert len(key) == 1
-                assert ord(key) < self.max_char
-                string_state[ord(key)] = chr(value)
-            string_states.extend(string_state)
-        self.states = "".join(string_states)
-        self.defaults = "".join(defaults)
+        self.states = states
         self.accepts = accepts
         self.start = start
 
     # ____________________________________________________________
-
-    def _next_state(self, item, crntState):
-        if ord(item) >= self.max_char:
-            return self.defaults[crntState]
-        else:
-            return self.states[crntState * self.max_char + ord(item)]
-
-    def recognize(self, inVec, pos = 0):
+    def recognize (self, inVec, pos = 0): # greedy = True
         crntState = self.start
         lastAccept = False
         i = pos
@@ -74,10 +38,13 @@
             item = inVec[i]
             if ord(item) > 0x80:
                 item = "\x80"  # NON_ASCII
+            # arcMap, accept = self.states[crntState]
+            arcMap = self.states[crntState]
             accept = self.accepts[crntState]
-            crntState = self._next_state(item, crntState)
-            if crntState != ERROR_STATE:
-                pass
+            if item in arcMap:
+                crntState = arcMap[item]
+            elif DEFAULT in arcMap:
+                crntState = arcMap[DEFAULT]
             elif accept:
                 return i
             elif lastAccept:
@@ -86,7 +53,6 @@
                 return i - 1
             else:
                 return -1
-            crntState = ord(crntState)
             lastAccept = accept
         # if self.states[crntState][1]:
         if self.accepts[crntState]:
@@ -99,20 +65,23 @@
 # ______________________________________________________________________
 
 class NonGreedyDFA (DFA):
-
-    def recognize(self, inVec, pos = 0):
+    def recognize (self, inVec, pos = 0):
         crntState = self.start
         i = pos
-        for i in range(pos, len(inVec)):
-            item = inVec[i]
+        for item in inVec[pos:]:
+            # arcMap, accept = self.states[crntState]
+            arcMap = self.states[crntState]
             accept = self.accepts[crntState]
             if accept:
                 return i
-            crntState = self._next_state(item, crntState)
-            if crntState == ERROR_STATE:
+            elif item in arcMap:
+                crntState = arcMap[item]
+            elif DEFAULT in arcMap:
+                crntState = arcMap[DEFAULT]
+            else:
                 return -1
-            crntState = ord(crntState)
             i += 1
+        # if self.states[crntState][1]:
         if self.accepts[crntState]:
             return i
         else:
--- a/ayrton/parser/unicodehelper.py
+++ b/ayrton/parser/unicodehelper.py
@@ -1,8 +1,7 @@
 import sys
-from pypy.interpreter.error import OperationError, oefmt
-from rpython.rlib.objectmodel import specialize
-from rpython.rlib import runicode
-from pypy.module._codecs import interp_codecs
+from ayrton.parser.error import OperationError, oefmt
+# from rpython.rlib import runicode
+# from ayrton.parser._codecs import interp_codecs
 _WIN32 = sys.platform == 'win32'
 _MACOSX = sys.platform == 'darwin'
 if _WIN32:
@@ -11,7 +10,6 @@
     # Workaround translator's confusion
     str_decode_mbcs = unicode_encode_mbcs = lambda *args, **kwargs: None
 
-@specialize.memo()
 def decode_error_handler(space):
     # Fast version of the "strict" errors handler.
     def raise_unicode_exception_decode(errors, encoding, msg, s,
@@ -24,7 +22,6 @@
                                              space.wrap(msg)]))
     return raise_unicode_exception_decode
 
-@specialize.memo()
 def encode_error_handler(space):
     # Fast version of the "strict" errors handler.
     def raise_unicode_exception_encode(errors, encoding, msg, u,
@@ -45,7 +42,6 @@
         self.end = end
         self.reason = reason
 
-@specialize.memo()
 def rpy_encode_error_handler():
     # A RPython version of the "strict" error handler.
     def raise_unicode_exception_encode(errors, encoding, msg, u,
@@ -120,13 +116,19 @@
     return encode_object(space, w_data, encoding, errors)
 
 # These functions take and return unwrapped rpython strings and unicodes
-def decode_unicode_escape(space, string):
-    state = space.fromcache(interp_codecs.CodecState)
-    unicodedata_handler = state.get_unicodedata_handler(space)
-    result, consumed = runicode.str_decode_unicode_escape(
-        string, len(string), "strict",
-        final=True, errorhandler=decode_error_handler(space),
-        unicodedata_handler=unicodedata_handler)
+# >>> from pypy.objspace.fake.objspace import FakeObjSpace
+# >>> space = FakeObjSpace ()
+# >>> decode_unicode_escape(space, 'aeyioiu')
+# u'a\xc3\xa1e\xc3\xa9y\xc3\xbdi\xc2\xb4oiu\xc3\xb3\xc2\xb4\xc5\xaf'
+# >>> decode_unicode_escape(space, u'aeyioiu')
+# u'a\xe1e\xe9y\xfdi\xb4oiu\xf3\xb4\u016f'
+
+# now, that kinda does not make any sense in py3:
+# >>> 'aeyioiu'.encode()
+# b'a\xc3\xa1e\xc3\xa9y\xc3\xbdi\xc2\xb4oiu\xc3\xb3\xc2\xb4\xc5\xaf'
+# 'aeyioiu'
+def decode_unicode_escape(string):
+    result = string
     return result
 
 def decode_raw_unicode_escape(space, string):
--- a/ayrton/parser/pyparser/parsestring.py
+++ b/ayrton/parser/pyparser/parsestring.py
@@ -1,32 +1,31 @@
 # coding: utf-8
-from pypy.interpreter.baseobjspace import W_Root
-from pypy.interpreter.error import OperationError, oefmt
-from pypy.interpreter import unicodehelper
-from rpython.rlib.rstring import StringBuilder
+from ayrton.parser.error import OperationError, oefmt
+from ayrton.parser import unicodehelper
+# from rpython.rlib.rstring import StringBuilder
+# import pdb
 
-
-class W_FString(W_Root):
+class W_FString():
     def __init__(self, unparsed, raw_mode):
-        assert isinstance(unparsed, str)    # utf-8 encoded string
-        self.unparsed = unparsed     # but the quotes are removed
+        assert isinstance(unparsed, bytes)    # utf-8 encoded bytes()
+        self.unparsed = unparsed              # but the quotes are removed
         self.raw_mode = raw_mode
         self.current_index = 0       # for astcompiler.fstring
 
 
-def parsestr(space, encoding, s):
-    """Parses a string or unicode literal, and return usually
+def parsestr(encoding, s):
+    """Parses a bytes() or str() literal, and return usually
     a wrapped value.  If we get an f-string, then instead return
     an unparsed but unquoted W_FString instance.
 
-    If encoding=None, the source string is ascii only.
-    In other cases, the source string is in utf-8 encoding.
+    s is a str()
 
-    When a bytes string is returned, it will be encoded with the
+    When bytes() is returned, it will be encoded with the
     original encoding.
 
     Yes, it's very inefficient.
     Yes, CPython has very similar code.
     """
+    # pdb.set_trace()
     # we use ps as "pointer to s"
     # q is the virtual last char index of the string
     ps = 0
@@ -91,9 +90,10 @@
         if encoding is None:
             substr = s[ps:q]
         else:
-            substr = decode_unicode_utf8(space, s, ps, q)
-        v = unicodehelper.decode_unicode_escape(space, substr)
-        return space.newunicode(v)
+            substr = decode_unicode_utf8(s, ps, q)
+        v = unicodehelper.decode_unicode_escape(substr)
+        # TODO: why unwarpped?
+        return v
 
     assert 0 <= ps <= q
     substr = s[ps : q]
@@ -102,7 +102,7 @@
         # Disallow non-ascii characters (but not escapes)
         for c in substr:
             if ord(c) > 0x80:
-                raise oefmt(space.w_SyntaxError,
+                raise oefmt(SyntaxError,
                             "bytes can only contain ASCII literal characters.")
 
     if rawmode or '\\' not in substr:
@@ -111,13 +111,14 @@
         elif saw_f:
             return W_FString(substr, rawmode)
         else:
-            v = unicodehelper.decode_utf8(space, substr)
-            return space.newunicode(v)
+            v = unicodehelper.decode_utf8(substr)
+            # TODO: why unwarpped?
+            return v
 
-    v = PyString_DecodeEscape(space, substr, 'strict', encoding)
+    v = PyString_DecodeEscape(substr, 'strict', encoding)
     return space.newbytes(v)
 
-def decode_unicode_utf8(space, s, ps, q):
+def decode_unicode_utf8(s, ps, q):
     # ****The Python 2.7 version, producing UTF-32 escapes****
     # String is utf8-encoded, but 'unicode_escape' expects
     # latin-1; So multibyte sequences must be escaped.
@@ -136,7 +137,7 @@
                 # instead.
                 lis.append("u005c")
         if ord(s[ps]) & 0x80: # XXX inefficient
-            w, ps = decode_utf8(space, s, ps, end)
+            w, ps = decode_utf8(s, ps, end)
             for c in w:
                 # The equivalent of %08x, which is not supported by RPython.
                 # 7 zeroes are enough for the unicode range, and the
@@ -149,7 +150,7 @@
             ps += 1
     return ''.join(lis)
 
-def PyString_DecodeEscape(space, s, errors, recode_encoding):
+def PyString_DecodeEscape(s, errors, recode_encoding):
     """
     Unescape a backslash-escaped string. If recode_encoding is non-zero,
     the string is UTF-8 encoded and should be re-encoded in the
@@ -163,7 +164,7 @@
             # note that the C code has a label here.
             # the logic is the same.
             if recode_encoding and ord(s[ps]) & 0x80:
-                w, ps = decode_utf8_recode(space, s, ps, end, recode_encoding)
+                w, ps = decode_utf8_recode(s, ps, end, recode_encoding)
                 # Append bytes to output buffer.
                 builder.append(w)
             else:
@@ -220,13 +221,13 @@
             else:
                 if errors == 'strict':
                     raise_app_valueerror(
-                        space, "invalid \\x escape at position %d" % (ps - 2))
+                        "invalid \\x escape at position %d" % (ps - 2))
                 elif errors == 'replace':
                     builder.append('?')
                 elif errors == 'ignore':
                     pass
                 else:
-                    raise oefmt(space.w_ValueError, "decoding error; "
+                    raise oefmt(ValueError, "decoding error; "
                         "unknown error handling code: %s", errors)
                 if ps+1 <= end and isxdigit(s[ps]):
                     ps += 1
@@ -250,20 +251,14 @@
             ch >= 'A' and ch <= 'F')
 
 
-def decode_utf8(space, s, ps, end):
+def decode_utf8(s, ps, end):
     assert ps >= 0
     pt = ps
     # while (s < end && *s != '\\') s++; */ /* inefficient for u".."
     while ps < end and ord(s[ps]) & 0x80:
         ps += 1
-    u = unicodehelper.decode_utf8(space, s[pt:ps])
+    u = unicodehelper.decode_utf8(s[pt:ps])
     return u, ps
 
-def decode_utf8_recode(space, s, ps, end, recode_encoding):
-    u, ps = decode_utf8(space, s, ps, end)
-    w_v = unicodehelper.encode(space, space.newunicode(u), recode_encoding)
-    v = space.bytes_w(w_v)
-    return v, ps
-
-def raise_app_valueerror(space, msg):
-    raise OperationError(space.w_ValueError, space.newtext(msg))
+def raise_app_valueerror(msg):
+    raise OperationError(ValueError, msg)
